<html><head><meta content="text/html; charset=UTF-8" http-equiv="content-type"><style type="text/css">.lst-kix_vp08mferwxv9-5>li:before{content:"\0025a0  "}.lst-kix_vp08mferwxv9-3>li:before{content:"\0025cf  "}.lst-kix_vp08mferwxv9-7>li:before{content:"\0025cb  "}.lst-kix_vp08mferwxv9-2>li:before{content:"\0025a0  "}.lst-kix_vp08mferwxv9-6>li:before{content:"\0025cf  "}.lst-kix_vp08mferwxv9-1>li:before{content:"\0025cb  "}ol.lst-kix_bj4jmq89m33u-7.start{counter-reset:lst-ctn-kix_bj4jmq89m33u-7 0}.lst-kix_bj4jmq89m33u-4>li{counter-increment:lst-ctn-kix_bj4jmq89m33u-4}.lst-kix_vp08mferwxv9-0>li:before{content:"\0025cf  "}.lst-kix_vp08mferwxv9-8>li:before{content:"\0025a0  "}ul.lst-kix_prbiw0ezw3h8-4{list-style-type:none}ul.lst-kix_prbiw0ezw3h8-5{list-style-type:none}ul.lst-kix_prbiw0ezw3h8-2{list-style-type:none}ul.lst-kix_prbiw0ezw3h8-3{list-style-type:none}ul.lst-kix_prbiw0ezw3h8-0{list-style-type:none}.lst-kix_bj4jmq89m33u-3>li{counter-increment:lst-ctn-kix_bj4jmq89m33u-3}ul.lst-kix_prbiw0ezw3h8-1{list-style-type:none}.lst-kix_bj4jmq89m33u-6>li{counter-increment:lst-ctn-kix_bj4jmq89m33u-6}ul.lst-kix_pgcx5w8qf1x6-0{list-style-type:none}ul.lst-kix_prbiw0ezw3h8-8{list-style-type:none}ul.lst-kix_prbiw0ezw3h8-6{list-style-type:none}ul.lst-kix_prbiw0ezw3h8-7{list-style-type:none}ul.lst-kix_yqt5lwbtzcl-8{list-style-type:none}ul.lst-kix_pgcx5w8qf1x6-6{list-style-type:none}ul.lst-kix_pgcx5w8qf1x6-5{list-style-type:none}ul.lst-kix_pgcx5w8qf1x6-8{list-style-type:none}ul.lst-kix_pgcx5w8qf1x6-7{list-style-type:none}ul.lst-kix_yqt5lwbtzcl-4{list-style-type:none}ul.lst-kix_pgcx5w8qf1x6-2{list-style-type:none}ul.lst-kix_yqt5lwbtzcl-5{list-style-type:none}ul.lst-kix_pgcx5w8qf1x6-1{list-style-type:none}ul.lst-kix_yqt5lwbtzcl-6{list-style-type:none}ul.lst-kix_pgcx5w8qf1x6-4{list-style-type:none}ul.lst-kix_yqt5lwbtzcl-7{list-style-type:none}ul.lst-kix_pgcx5w8qf1x6-3{list-style-type:none}ul.lst-kix_yqt5lwbtzcl-0{list-style-type:none}ul.lst-kix_yqt5lwbtzcl-1{list-style-type:none}ul.lst-kix_yqt5lwbtzcl-2{list-style-type:none}ul.lst-kix_yqt5lwbtzcl-3{list-style-type:none}.lst-kix_vp08mferwxv9-4>li:before{content:"\0025cb  "}.lst-kix_ogj0id8mrzjk-1>li:before{content:"\0025cb  "}.lst-kix_ogj0id8mrzjk-0>li:before{content:"\0025cf  "}.lst-kix_ogj0id8mrzjk-6>li:before{content:"\0025cf  "}.lst-kix_ogj0id8mrzjk-5>li:before{content:"\0025a0  "}.lst-kix_ogj0id8mrzjk-2>li:before{content:"\0025a0  "}ol.lst-kix_bj4jmq89m33u-5.start{counter-reset:lst-ctn-kix_bj4jmq89m33u-5 0}.lst-kix_ogj0id8mrzjk-4>li:before{content:"\0025cb  "}.lst-kix_ogj0id8mrzjk-3>li:before{content:"\0025cf  "}ul.lst-kix_vp08mferwxv9-1{list-style-type:none}ul.lst-kix_vp08mferwxv9-2{list-style-type:none}ul.lst-kix_vp08mferwxv9-3{list-style-type:none}ul.lst-kix_vp08mferwxv9-4{list-style-type:none}.lst-kix_yqt5lwbtzcl-8>li:before{content:"\0025a0  "}.lst-kix_yqt5lwbtzcl-7>li:before{content:"\0025cb  "}ul.lst-kix_vp08mferwxv9-0{list-style-type:none}.lst-kix_yqt5lwbtzcl-6>li:before{content:"\0025cf  "}.lst-kix_yqt5lwbtzcl-5>li:before{content:"\0025a0  "}ul.lst-kix_ogj0id8mrzjk-1{list-style-type:none}.lst-kix_yqt5lwbtzcl-2>li:before{content:"\0025a0  "}.lst-kix_bj4jmq89m33u-5>li{counter-increment:lst-ctn-kix_bj4jmq89m33u-5}ul.lst-kix_r92oh920e7v5-8{list-style-type:none}ul.lst-kix_ogj0id8mrzjk-0{list-style-type:none}ul.lst-kix_r92oh920e7v5-7{list-style-type:none}ul.lst-kix_r92oh920e7v5-6{list-style-type:none}ul.lst-kix_r92oh920e7v5-5{list-style-type:none}.lst-kix_yqt5lwbtzcl-0>li:before{content:"\0025cf  "}.lst-kix_yqt5lwbtzcl-4>li:before{content:"\0025cb  "}.lst-kix_yqt5lwbtzcl-3>li:before{content:"\0025cf  "}.lst-kix_bj4jmq89m33u-2>li{counter-increment:lst-ctn-kix_bj4jmq89m33u-2}ul.lst-kix_r92oh920e7v5-0{list-style-type:none}ul.lst-kix_ogj0id8mrzjk-8{list-style-type:none}ul.lst-kix_ogj0id8mrzjk-7{list-style-type:none}ul.lst-kix_ogj0id8mrzjk-6{list-style-type:none}ul.lst-kix_ogj0id8mrzjk-5{list-style-type:none}ol.lst-kix_bj4jmq89m33u-4.start{counter-reset:lst-ctn-kix_bj4jmq89m33u-4 0}ul.lst-kix_vp08mferwxv9-5{list-style-type:none}ul.lst-kix_r92oh920e7v5-4{list-style-type:none}ul.lst-kix_ogj0id8mrzjk-4{list-style-type:none}ul.lst-kix_vp08mferwxv9-6{list-style-type:none}ul.lst-kix_r92oh920e7v5-3{list-style-type:none}ul.lst-kix_ogj0id8mrzjk-3{list-style-type:none}.lst-kix_yqt5lwbtzcl-1>li:before{content:"\0025cb  "}.lst-kix_bj4jmq89m33u-8>li{counter-increment:lst-ctn-kix_bj4jmq89m33u-8}ul.lst-kix_vp08mferwxv9-7{list-style-type:none}ul.lst-kix_r92oh920e7v5-2{list-style-type:none}ul.lst-kix_ogj0id8mrzjk-2{list-style-type:none}ul.lst-kix_vp08mferwxv9-8{list-style-type:none}ul.lst-kix_r92oh920e7v5-1{list-style-type:none}.lst-kix_jrgvomkt7wgu-4>li:before{content:"\0025cb  "}.lst-kix_jrgvomkt7wgu-3>li:before{content:"\0025cf  "}.lst-kix_jrgvomkt7wgu-5>li:before{content:"\0025a0  "}.lst-kix_jrgvomkt7wgu-2>li:before{content:"\0025a0  "}.lst-kix_jrgvomkt7wgu-6>li:before{content:"\0025cf  "}.lst-kix_jrgvomkt7wgu-0>li:before{content:"\0025cf  "}.lst-kix_jrgvomkt7wgu-8>li:before{content:"\0025a0  "}.lst-kix_jrgvomkt7wgu-1>li:before{content:"\0025cb  "}.lst-kix_jrgvomkt7wgu-7>li:before{content:"\0025cb  "}.lst-kix_pgcx5w8qf1x6-0>li:before{content:"-  "}.lst-kix_pgcx5w8qf1x6-1>li:before{content:"-  "}.lst-kix_bj4jmq89m33u-5>li:before{content:"" counter(lst-ctn-kix_bj4jmq89m33u-5,lower-roman) ". "}.lst-kix_pgcx5w8qf1x6-2>li:before{content:"-  "}.lst-kix_bj4jmq89m33u-6>li:before{content:"" counter(lst-ctn-kix_bj4jmq89m33u-6,decimal) ". "}.lst-kix_pgcx5w8qf1x6-3>li:before{content:"-  "}.lst-kix_bj4jmq89m33u-7>li:before{content:"" counter(lst-ctn-kix_bj4jmq89m33u-7,lower-latin) ". "}.lst-kix_pgcx5w8qf1x6-6>li:before{content:"-  "}ol.lst-kix_bj4jmq89m33u-8.start{counter-reset:lst-ctn-kix_bj4jmq89m33u-8 0}.lst-kix_bj4jmq89m33u-8>li:before{content:"" counter(lst-ctn-kix_bj4jmq89m33u-8,lower-roman) ". "}.lst-kix_pgcx5w8qf1x6-4>li:before{content:"-  "}.lst-kix_pgcx5w8qf1x6-5>li:before{content:"-  "}ol.lst-kix_bj4jmq89m33u-0.start{counter-reset:lst-ctn-kix_bj4jmq89m33u-0 0}ol.lst-kix_bj4jmq89m33u-3.start{counter-reset:lst-ctn-kix_bj4jmq89m33u-3 0}.lst-kix_pgcx5w8qf1x6-7>li:before{content:"-  "}.lst-kix_r92oh920e7v5-8>li:before{content:"\0025a0  "}.lst-kix_r92oh920e7v5-7>li:before{content:"\0025cb  "}.lst-kix_ogj0id8mrzjk-8>li:before{content:"\0025a0  "}.lst-kix_pgcx5w8qf1x6-8>li:before{content:"-  "}.lst-kix_ogj0id8mrzjk-7>li:before{content:"\0025cb  "}.lst-kix_r92oh920e7v5-4>li:before{content:"\0025cb  "}ol.lst-kix_bj4jmq89m33u-6.start{counter-reset:lst-ctn-kix_bj4jmq89m33u-6 0}.lst-kix_r92oh920e7v5-3>li:before{content:"\0025cf  "}.lst-kix_r92oh920e7v5-5>li:before{content:"\0025a0  "}.lst-kix_bj4jmq89m33u-4>li:before{content:"" counter(lst-ctn-kix_bj4jmq89m33u-4,lower-latin) ". "}.lst-kix_r92oh920e7v5-2>li:before{content:"\0025a0  "}.lst-kix_r92oh920e7v5-6>li:before{content:"\0025cf  "}.lst-kix_bj4jmq89m33u-3>li:before{content:"" counter(lst-ctn-kix_bj4jmq89m33u-3,decimal) ". "}.lst-kix_bj4jmq89m33u-0>li:before{content:"" counter(lst-ctn-kix_bj4jmq89m33u-0,decimal) ". "}.lst-kix_bj4jmq89m33u-2>li:before{content:"" counter(lst-ctn-kix_bj4jmq89m33u-2,lower-roman) ". "}.lst-kix_bj4jmq89m33u-1>li:before{content:"" counter(lst-ctn-kix_bj4jmq89m33u-1,lower-latin) ". "}.lst-kix_bj4jmq89m33u-7>li{counter-increment:lst-ctn-kix_bj4jmq89m33u-7}.lst-kix_bj4jmq89m33u-1>li{counter-increment:lst-ctn-kix_bj4jmq89m33u-1}.lst-kix_r92oh920e7v5-1>li:before{content:"\0025cb  "}ol.lst-kix_bj4jmq89m33u-2.start{counter-reset:lst-ctn-kix_bj4jmq89m33u-2 0}.lst-kix_r92oh920e7v5-0>li:before{content:"\0025cf  "}.lst-kix_prbiw0ezw3h8-8>li:before{content:"\0025a0  "}.lst-kix_prbiw0ezw3h8-5>li:before{content:"\0025a0  "}.lst-kix_prbiw0ezw3h8-6>li:before{content:"\0025cf  "}.lst-kix_prbiw0ezw3h8-7>li:before{content:"\0025cb  "}.lst-kix_bj4jmq89m33u-0>li{counter-increment:lst-ctn-kix_bj4jmq89m33u-0}.lst-kix_prbiw0ezw3h8-1>li:before{content:"\0025cb  "}.lst-kix_prbiw0ezw3h8-0>li:before{content:"\0025cf  "}.lst-kix_prbiw0ezw3h8-2>li:before{content:"\0025a0  "}ul.lst-kix_jrgvomkt7wgu-7{list-style-type:none}ul.lst-kix_jrgvomkt7wgu-8{list-style-type:none}ul.lst-kix_jrgvomkt7wgu-5{list-style-type:none}ul.lst-kix_jrgvomkt7wgu-6{list-style-type:none}.lst-kix_prbiw0ezw3h8-4>li:before{content:"\0025cb  "}.lst-kix_prbiw0ezw3h8-3>li:before{content:"\0025cf  "}li.li-bullet-0:before{margin-left:-18pt;white-space:nowrap;display:inline-block;min-width:18pt}ol.lst-kix_bj4jmq89m33u-1{list-style-type:none}ol.lst-kix_bj4jmq89m33u-0{list-style-type:none}ol.lst-kix_bj4jmq89m33u-3{list-style-type:none}ol.lst-kix_bj4jmq89m33u-2{list-style-type:none}ol.lst-kix_bj4jmq89m33u-1.start{counter-reset:lst-ctn-kix_bj4jmq89m33u-1 0}ul.lst-kix_jrgvomkt7wgu-3{list-style-type:none}ol.lst-kix_bj4jmq89m33u-8{list-style-type:none}ul.lst-kix_jrgvomkt7wgu-4{list-style-type:none}ul.lst-kix_jrgvomkt7wgu-1{list-style-type:none}ul.lst-kix_jrgvomkt7wgu-2{list-style-type:none}ol.lst-kix_bj4jmq89m33u-5{list-style-type:none}ol.lst-kix_bj4jmq89m33u-4{list-style-type:none}ul.lst-kix_jrgvomkt7wgu-0{list-style-type:none}ol.lst-kix_bj4jmq89m33u-7{list-style-type:none}ol.lst-kix_bj4jmq89m33u-6{list-style-type:none}ol{margin:0;padding:0}table td,table th{padding:0}.c10{border-right-style:solid;padding:5pt 5pt 5pt 5pt;border-bottom-color:#000000;border-top-width:1pt;border-right-width:1pt;border-left-color:#000000;vertical-align:top;border-right-color:#000000;border-left-width:1pt;border-top-style:solid;border-left-style:solid;border-bottom-width:1pt;width:468pt;border-top-color:#000000;border-bottom-style:solid}.c20{border-right-style:solid;padding:5pt 5pt 5pt 5pt;border-bottom-color:#000000;border-top-width:1pt;border-right-width:1pt;border-left-color:#000000;vertical-align:top;border-right-color:#000000;border-left-width:1pt;border-top-style:solid;border-left-style:solid;border-bottom-width:1pt;width:135.8pt;border-top-color:#000000;border-bottom-style:solid}.c12{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:16pt;font-family:"Arial";font-style:normal}.c33{padding-top:0pt;padding-bottom:3pt;line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}.c5{color:#434343;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:14pt;font-family:"Arial";font-style:normal}.c3{padding-top:14pt;padding-bottom:4pt;line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}.c29{padding-top:0pt;padding-bottom:16pt;line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}.c9{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:11pt;font-family:"Arial";font-style:italic}.c23{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:26pt;font-family:"Arial";font-style:normal}.c1{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:11pt;font-family:"Arial";font-style:normal}.c18{color:#666666;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:15pt;font-family:"Arial";font-style:normal}.c17{padding-top:16pt;padding-bottom:4pt;line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}.c0{padding-top:18pt;padding-bottom:6pt;line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}.c7{color:#666666;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:12pt;font-family:"Arial";font-style:normal}.c31{padding-top:0pt;padding-bottom:0pt;line-height:1.15;orphans:2;widows:2;text-align:center}.c2{padding-top:0pt;padding-bottom:0pt;line-height:1.15;orphans:2;widows:2;text-align:left}.c4{padding-top:0pt;padding-bottom:0pt;line-height:1.0;text-align:left}.c26{border-spacing:0;border-collapse:collapse;margin-right:auto}.c8{text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;text-decoration:underline}.c25{background-color:#ffffff;max-width:468pt;padding:72pt 72pt 72pt 72pt}.c22{margin-left:36pt;padding-left:0pt}.c11{color:inherit;text-decoration:inherit}.c15{padding:0;margin:0}.c24{margin-left:36pt}.c27{height:48.8pt}.c6{height:11pt}.c19{height:14pt}.c32{margin-left:108pt}.c13{height:7.5pt}.c21{height:49.5pt}.c16{font-style:italic}.c14{height:0pt}.c28{height:27.2pt}.c30{height:27pt}.title{padding-top:0pt;color:#000000;font-size:26pt;padding-bottom:3pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}.subtitle{padding-top:0pt;color:#666666;font-size:15pt;padding-bottom:16pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}li{color:#000000;font-size:11pt;font-family:"Arial"}p{margin:0;color:#000000;font-size:11pt;font-family:"Arial"}h1{padding-top:20pt;color:#000000;font-size:20pt;padding-bottom:6pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h2{padding-top:18pt;color:#000000;font-size:16pt;padding-bottom:6pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h3{padding-top:16pt;color:#434343;font-size:14pt;padding-bottom:4pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h4{padding-top:14pt;color:#666666;font-size:12pt;padding-bottom:4pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h5{padding-top:12pt;color:#666666;font-size:11pt;padding-bottom:4pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h6{padding-top:12pt;color:#666666;font-size:11pt;padding-bottom:4pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;font-style:italic;orphans:2;widows:2;text-align:left}</style></head><body class="c25"><div><p class="c2 c6"><span class="c1"></span></p></div><p class="c33 title" id="h.k6v4307u1w1k"><span class="c23">Social Media Content Filter</span></p><p class="c29 subtitle" id="h.dhy770g9jxnl"><span>By: </span><span class="c8"><a class="c11" href="https://www.google.com/url?q=https://github.com/drkinder&amp;sa=D&amp;source=editors&amp;ust=1639840691539000&amp;usg=AOvVaw3J_03ssiHqaffwOPLmb4vr">Dylan Kinder</a></span><span>, </span><span class="c8"><a class="c11" href="https://www.google.com/url?q=https://github.com/rmaloney820&amp;sa=D&amp;source=editors&amp;ust=1639840691540000&amp;usg=AOvVaw3jG5ONXgyNQFDgAywziwaZ">Ryan Maloney</a></span><span>, and </span><span class="c8"><a class="c11" href="https://www.google.com/url?q=https://github.com/mphillipsjr96&amp;sa=D&amp;source=editors&amp;ust=1639840691540000&amp;usg=AOvVaw0O7LZzHBSG8Ct1_1T6r6Sz">Michael Phillips</a></span></p><h2 class="c0" id="h.n8867cy4zad7"><span class="c12">Introduction</span></h2><p class="c2"><span class="c1">Social media has become flooded with negativity, pessimism, etc. People don&rsquo;t like to see that stuff and neither do we. So, we took it upon ourselves to create this social media content filter initially focused on Twitter to remove some of that negativity and clean up our feeds. </span></p><p class="c2 c6"><span class="c1"></span></p><h2 class="c0" id="h.c878fwc4oc4z"><span class="c12">The Chrome Extension</span></h2><p class="c2"><span class="c8"><a class="c11" href="https://www.google.com/url?q=https://drive.google.com/file/d/13yO6mPtxTqj4AYpi_U0MChJdoHegSXhH/view?usp%3Dsharing&amp;sa=D&amp;source=editors&amp;ust=1639840691541000&amp;usg=AOvVaw0z7d1-q7YggxCTonIupYj-">Video</a></span></p><p class="c2 c6"><span class="c1"></span></p><h3 class="c17" id="h.q0qc7v42y9lp"><span class="c5">Architecture Overview</span></h3><p class="c2"><span class="c1">The Chrome Extension required a full stack web application with the frontend being the Chrome Extension running HTML, CSS, and JavaScript in the browser with a Python-powered API deployed in Google Cloud. For a high level overview of the architecture and a glimpse at our classification algorithm, refer to the following flowchart.</span></p><p class="c2 c6"><span class="c1"></span></p><p class="c2"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 416.39px; height: 535.50px;"><img alt="" src="images/image13.jpg" style="width: 416.39px; height: 535.50px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><h3 class="c17" id="h.dnqc2aupg6qd"><span>Backend</span></h3><h4 class="c3" id="h.kyq0s2f040n9"><span>API Framework</span></h4><p class="c2"><span class="c1">We used the Python library fastapi to build a few API endpoints for the extension. We chose this framework primarily for its simplicity and speed. We did not want our extension to alter the user experience of Twitter and needed a light and fast framework. Additionally, our extension relies on a single endpoint without user authentication, so there is no need for additional functionality that threatens the speed that our API can handle requests. We also appreciated the simplicity of fastapi&rsquo;s self-generating API documentation. </span></p><h4 class="c3" id="h.c9qx0lek0cb7"><span>Google Cloud Platform</span></h4><p class="c2"><span class="c1">The API was deployed on Google Cloud Platform (GCP) through Cloud Build. The extension relies on Cloud Run to handle requests and run our machine learning models. Cloud Run is stateless, significantly reducing the monthly cost as Cloud Run only runs and charges when serving requests. The alternative service to Cloud Run in GCP for this project would be App Engine, which runs and charges for running 24/7. Cloud Run is often 90-99% cheaper than using App Engine.</span></p><p class="c2 c6"><span class="c1"></span></p><p class="c2"><span class="c1">Through Cloud Build, we were able to streamline our development process through triggering an automatic cloud rebuild whenever an update is pushed to our API GitHub repository&rsquo;s main branch. This allowed everyone to work asynchronously to build better models and quickly deploy them to the cloud for live testing. </span></p><h4 class="c3" id="h.oah5kfb4okdg"><span class="c7">Serving Predictions - Endpoints</span></h4><p class="c2"><span>Automatically generated API documentation is available </span><span class="c8"><a class="c11" href="https://www.google.com/url?q=https://content-filter-api-js23pan5iq-uc.a.run.app/docs%23/&amp;sa=D&amp;source=editors&amp;ust=1639840691542000&amp;usg=AOvVaw1tXa5_AIBf2yTEyiPvjvi1">here</a></span><span class="c1">. There are multiple endpoints available, each mapping to different classification models. Every endpoint is accessible via POST method and expects the same request body structure. Our best performing model lives under the /filter-twitter-content/ endpoint. Below is an example cURL request to this endpoint:</span></p><p class="c2 c6"><span class="c1"></span></p><a id="t.9fe34a6f7c0018c9d2389ebf2bb8fd00969305e9"></a><a id="t.0"></a><table class="c26"><tbody><tr class="c14"><td class="c10" colspan="1" rowspan="1"><p class="c4"><span class="c1">curl --location --request POST &#39;https://content-filter-api-js23pan5iq-uc.a.run.app/filter-twitter-content/&#39; \</span></p><p class="c4"><span class="c1">--header &#39;Content-Type: application/json&#39; \</span></p><p class="c4"><span class="c1">--data-raw &#39;{</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; &quot;body&quot;: &quot;This is an example of a Tweet&rsquo;s content&quot;,</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; &quot;threshold&quot;: 0.55,</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; &quot;filter_words&quot;: [</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; &nbsp; &nbsp; &quot;test&quot;,</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; &nbsp; &nbsp; &ldquo;example&rdquo;</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; ]</span></p><p class="c4"><span class="c1">}&#39;</span></p></td></tr></tbody></table><p class="c2 c6"><span class="c1"></span></p><p class="c2"><span class="c1">Note: the JSON body keys &ldquo;filter_words&rdquo; and &ldquo;threshold&rdquo; are optional. If not provided, they will take the default values of [] and 0.55 respectively.</span></p><p class="c2 c6"><span class="c1"></span></p><p class="c2"><span class="c1">The threshold variable can be used to control the classification cutoff of the model. If the predicted probability of a Tweet being positive is less than or equal to the threshold, it will be classified as &ldquo;negative&rdquo; and filtered. The filtered_words variable allows users the option to provide a list of words or topics they would like to filter from their Twitter feed. In this case, in addition to checking for negativity, the Tweet will also be analyzed to determine whether it&rsquo;s text explicitly includes or includes related topics to any of the words in the filter_words list. If using this option, it&rsquo;s possible that even Tweets with very high probability of being positive will be filtered out if the Tweet is determined to be related to any of the words in the filter_words list.</span></p><p class="c2 c6"><span class="c1"></span></p><p class="c2"><span class="c1">An example response from the API is shown below:</span></p><p class="c2 c6"><span class="c1"></span></p><a id="t.ed240b2411cd37346ec7a8ee0566aa047638886c"></a><a id="t.1"></a><table class="c26"><tbody><tr class="c14"><td class="c10" colspan="1" rowspan="1"><p class="c4"><span class="c1">{</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; &quot;filter&quot;: bool,</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; &quot;confidence_positive&quot;: float</span></p><p class="c4"><span class="c1">}</span></p></td></tr></tbody></table><p class="c2 c6"><span class="c1"></span></p><p class="c2"><span class="c1">filter: should the Tweet be filtered?</span></p><p class="c2"><span>confidence_positive: range 0 to 1 of how confident the model is that the Tweet is positive.</span></p><h3 class="c17" id="h.btlay9ptggha"><span class="c5">Frontend</span></h3><h4 class="c3" id="h.w87r6zhrbz5v"><span class="c7">Design Goals</span></h4><p class="c2"><span>In an effort to address the ethical implications of altering the content visible in a user&rsquo;s Twitter feed, we tried to provide as much control to the user as possible. First, it was important to us that each user could set their own </span><span class="c16">negativity threshold</span><span class="c1">, which we achieved through the use of a horizontal slider. We also wanted to provide the opportunity for users to choose specific words or topics of content that they would like to filter from their Twitter feeds. We felt that with these two parameters left to the control of each individual user, they would be better equipped to use the Chrome extension in a way that is beneficial to them. An additional goal was to make the interface as easy to use and to understand as possible. Working with an extension creates space restrictions so it was necessary to keep our design compact without suffering loss in usability.</span></p><h4 class="c3" id="h.meuavylghvh7"><span class="c7">The Slider - Negativity Threshold</span></h4><p class="c2"><span class="c1">The slider in the Chrome extension controls the threshold parameter. This threshold parameter acts as the minimum cutoff predicted probability of a Tweet being positive required for the Tweet to appear in a user&rsquo;s feed. In practice, increasing the threshold will hide more and more content while decreasing the threshold will allow more and more to be shown in the user&rsquo;s feed. Because threshold maps directly to predicted probability, it must range between 0 and 1. </span></p><p class="c2 c6"><span class="c1"></span></p><p class="c2"><span class="c1">We considered allowing the user to type in a threshold value but found it much less user friendly than a slider. The first version of the slider used 0 and 1 as labels for the extreme positions but we had concerns that it might be challenging for some users to conceptualize the significance of 0 and 1. Effectively communicating the significance of these numbers was made even more difficult due to the limited space available in a Chrome extension. For these reasons, we decided to change the labels to the more intuitive values &ldquo;less&rdquo; and &ldquo;more&rdquo; and changed the slider label from the vague &ldquo;Negativity Threshold&rdquo; to &ldquo;How much negativity are you willing to tolerate?&rdquo;. Because it makes more intuitive sense that decreasing the slider value aligns with the label &ldquo;less&rdquo; and increasing it aligns with the label &ldquo;more&rdquo;, we also had to inverse the slider so that it ranged from 1 at the left-most position and 0 at the right-most.</span></p><p class="c2 c6"><span class="c1"></span></p><p class="c2"><span class="c1">One of our most important goals for this project was to avoid harming the user experience of Twitter. We aimed to have our Chrome extension running silently in the background. We didn&rsquo;t want the user to have to wait any longer than normal for new Tweets to load, cause the page to crash, or any visible strange behavior such as Tweets disappearing. To support this objective, we decided to limit the threshold value that the user can select between 0.2 and 0.8. Without limiting, setting the threshold to 0 would not filter anything while setting it to 1 would filter everything and essentially break Twitter. Restricting the max threshold to 0.8 helps prevent this; however, it&rsquo;s possible even with a maximum threshold of 0.8, the user may still experience disruptions as the majority of Twitter content does not receive a prediction probability of being 0.8 likely positive or more. For the lower limit of 0.2, we found our model performed exceptionally well at correctly classifying negative Tweets if its probability of the Tweet being positive was below 0.2. Visualizing the accuracy at or below this threshold level provided a clear cutoff value, where anything under 0.2 predicted probability of being positive is very likely indeed negative. We would like to continue optimizing the maximum and minimum threshold values, as well as the best default value in the future.</span></p><h4 class="c3" id="h.fhxal1hbho79"><span class="c7">Word/Topic Filtering</span></h4><p class="c2"><span class="c1">Fortunately for us, the idea of filtering specific words or topics is much easier to conceptualize than prediction probability cutoff values. The current Chrome extension allows the user to easily type in a word to filter and click a button to add it to the list which appears in the extension as two columns of words. If the word or topic is long, it will dynamically adjust the position to put the word in a single row, even spanning multiple lines if the keyword is long enough. Every keyword has an &ldquo;x&rdquo; to the left of it, allowing the user to individually remove words previously added.</span></p><h4 class="c3" id="h.cwt5g06y0hqg"><span class="c7">Reset to Default Settings</span></h4><p class="c2"><span class="c1">Through our personal experience testing and working with the extension, we realized clearing many words added to the filter list at once was cumbersome. Each word required its own click to clear. In an effort to speed up clearing the filtered word list, we added a button to the button labeled &ldquo;Reset to Default Settings&rdquo;. This button will also reset the negativity threshold slider to the default 0.5 middle position.</span></p><h3 class="c17" id="h.ogb31v4qkxyj"><span class="c5">Twitter</span></h3><h4 class="c3" id="h.7pxthec75xq0"><span class="c7">Supported Pages</span></h4><p class="c2"><span>The extension in its current state works on /home, /explore, and user profiles. Because Twitter is a single-page application, it was challenging to determine which page the user is on. If the page refreshed when switching between pages, it would have been easier to listen for this and update the page accordingly. Instead we opted to determine the page based on the aria-label property of the HTML div element of the Timeline (the center console where Tweets are rendered). We appreciated this human-readable page label. Examples of this property for the Home page and the Explore page are &ldquo;Timeline: Your Home Timeline&rdquo; and &ldquo;Timeline: Explore&rdquo;. These proved to be a reliable method for quickly determining which page the user was on. The page the user is on requires slightly different logic to properly capture, render, and hide Tweets.</span></p><h4 class="c3" id="h.ojocrjg0ugwt"><span>Classifying Tweets</span></h4><p class="c2"><span class="c1">Because our model must be loaded into memory on the backend for each API request, we had hoped to bundle multiple Tweets in every request to reduce the workload of our server and therefore, increase prediction speed. Unfortunately, the way that Twitter loads new Tweets complicates this objective. Twitter begins by loading three Tweets, allowing us to bundle these initial Tweets into a single request; however, all following Tweets are loaded individually as the user scrolls down their Timeline. To avoid disruption in the user experience of Twitter, we were forced to also classify each Tweet individually. Fortunately, our server appears to be handling this well supporting at least a few users concurrently. The exact number of concurrent users that our API can support remains unclear.</span></p><h4 class="c3" id="h.tyi6tsi7xqr0"><span class="c7">Hiding Negative Tweets</span></h4><p class="c2"><span>We initially tried to capture the entire HTML content of the Tweet and hold it from being inserted into Twitter&rsquo;s Timeline. This approach was very difficult to manage and introduced disruptions in the user experience. Our second approach was to allow the HTML for a new Tweet to be loaded into the Timeline; however, we would apply some CSS to it so that it would be completely invisible for the user. After sending the content of the Tweet to our model, we could use the prediction to determine whether to remove our CSS, allowing the user to see it. Under normal scrolling conditions, new Tweets are loaded in before the scrolling user arrives at them providing time for our extension, API, and model to run before the user arrives at the Tweet so there are usually not strange situations where Tweets just &ldquo;appear&rdquo; on the screen after the pipeline returns a decision. With this said, scrolling extremely quickly, too fast to read any of the Tweets can produce instances of this strange behavior. </span></p><h3 class="c17" id="h.jc6tkqnr16i5"><span class="c5">Download and Installation Instructions</span></h3><ol class="c15 lst-kix_bj4jmq89m33u-0 start" start="1"><li class="c2 c22 li-bullet-0"><span>Download the Chrome Extension from Github </span><span class="c8"><a class="c11" href="https://www.google.com/url?q=https://github.com/drkinder/content-filter-chrome-extension&amp;sa=D&amp;source=editors&amp;ust=1639840691549000&amp;usg=AOvVaw0zaIQ7ORjHhmCPdW10wN_O">here</a></span><span class="c1">.</span></li><li class="c2 c22 li-bullet-0"><span class="c1">Open your Google Chrome Browser and click on the puzzle icon at the top right corner of the browser, just below the minimize, resize, and exit buttons. </span></li><li class="c2 c22 li-bullet-0"><span class="c1">Click on &quot;Manage Extensions&quot;. </span></li><li class="c2 c22 li-bullet-0"><span class="c1">Check the top right corner to make sure &ldquo;Developer Mode&rdquo; is toggled on. </span></li><li class="c2 c22 li-bullet-0"><span class="c1">Now in the top left corner of the page, click &ldquo;Load unpacked&rdquo;. </span></li><li class="c2 c22 li-bullet-0"><span class="c1">Find the extension directory on your computer downloaded from GitHub and select it. You should see a card with the label &ldquo;Content Filter&rdquo; appear in your list of installed Extensions. Note: if you see an error about a missing manifest.json file, make sure you select the directory containing the manifest.json file.</span></li><li class="c2 c22 li-bullet-0"><span class="c1">Pin this extension to your browser to make interacting with it easier by clicking the puzzle piece icon again, find &quot;Twitter Content Filter&quot; and click the pin icon. </span></li><li class="c2 c22 li-bullet-0"><span class="c1">Go to Twitter or refresh Twitter if you were already on the page before loading the extension. The extension will begin working in the background with default settings. To add your own customer words to filter and tune the filter threshold to your preferred settings, click on the pinned extension with the letter &quot;T&quot;.</span></li></ol><p class="c2 c6"><span class="c1"></span></p><h2 class="c0" id="h.s3ig6cz12dxf"><span>Preprocessing</span></h2><p class="c2"><span class="c1">We took a handful of steps to preprocess our training data and, in turn, the live tweets as they pass through our model. The first step we took was to tokenize and lemmatize the tweets by passing them through the preprocess_string() function from gensim. Once they were processed, we removed stop words from the tokens. To create a better set of training data, we also created bigrams using the Phrases() function from gensim. We created those bigrams when two words appeared next to each other at least 20 times.</span></p><p class="c2 c6"><span class="c1"></span></p><a id="t.f17de58a04dda88def595e8f13be93e03ff2ac6a"></a><a id="t.2"></a><table class="c26"><tbody><tr class="c13"><td class="c10" colspan="1" rowspan="1"><p class="c2"><span class="c1">phrase_model = Phrases(tweet_df[&#39;tokens&#39;],min_count=20,threshold=2).freeze()</span></p></td></tr></tbody></table><h2 class="c0" id="h.sj7i0p22vzw9"><span class="c12">Models</span></h2><p class="c2"><span>In order to get the best results we could, we experimented with numerous different models with different parameters. We looked into Latent Semantic Indexing (LSI), Latent Dirichlet Allocation (LDA), Word Embeddings, and FastText Embeddings.</span></p><h3 class="c17" id="h.swak27qoyhve"><span class="c5">Latent Semantic Indexing</span></h3><p class="c2"><span class="c1">For LSI, we utilized pipelines for our model testing. Each pipeline started off with a CountVectorizer, then a TFIDFTransformer, and finally the specific model.</span></p><p class="c2 c6"><span class="c1"></span></p><a id="t.03b908fdccccdf733c28b07f134ff7f9923f668f"></a><a id="t.3"></a><table class="c26"><tbody><tr class="c21"><td class="c10" colspan="1" rowspan="1"><p class="c4"><span class="c1">Pipeline([(&#39;vect&#39;, CountVectorizer(stop_words=&#39;english&#39;,ngram_range=(1,3))),</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;(&#39;tfidf&#39;, TfidfTransformer(use_idf=False)),</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; (&#39;clf&#39;, &nbsp;model)])</span></p></td></tr></tbody></table><p class="c2 c6"><span class="c1"></span></p><p class="c2"><span>While hyper-tuning the parameters, we utilized GridSearch. This was used to identify the &ldquo;best&rdquo; parameters for our models, given a list of parameters to try. GridSearch execution was quite lengthy as it tested each combination of parameters that we gave it. Sometimes the run time was over 24 hours.</span></p><p class="c2 c6 c32"><span class="c1"></span></p><p class="c2"><span>The models we used for LSI were Multinomial Naive Bayes, </span><span class="c1">Stochastic Gradient Descent Classifier, and Linear Support Vector Classifier. We chose these models because we need to classify whether a Tweet is negative or positive(neutral). These also gave us the ability to see how negative a Tweet was instead of just classifying it as negative or positive. This allowed the use of the slider function as mentioned above.</span></p><h4 class="c3" id="h.r2mhosr87smx"><span class="c7">Multinomial Naive Bayes</span></h4><a id="t.839931d06d2f3a145e4b7ce9d6a493d27f3919be"></a><a id="t.4"></a><table class="c26"><tbody><tr class="c30"><td class="c20" colspan="1" rowspan="1"><p class="c4"><span class="c1">model = MultinomialNB()</span></p></td></tr></tbody></table><p class="c2 c6"><span class="c1"></span></p><h4 class="c3" id="h.9qeqr9242n2x"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 379.00px; height: 123.00px;"><img alt="" src="images/image8.png" style="width: 379.00px; height: 123.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 224.35px; height: 200.35px;"><img alt="" src="images/image14.png" style="width: 224.35px; height: 200.35px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></h4><p class="c2"><span class="c9">0 is negative, 4 is positive</span></p><p class="c2"><span>MNB had the best recall for negative tweets. It&rsquo;s performance was similar to LinearSVC. It had similar size to LinearSVC, but about 1% less accuracy on average.</span></p><h4 class="c3" id="h.y66wif8h488n"><span class="c7">Stochastic Gradient Descent Classifier</span></h4><a id="t.4a0590c476aae4dc1c5bce562b1594956e54e563"></a><a id="t.5"></a><table class="c26"><tbody><tr class="c28"><td class="c10" colspan="1" rowspan="1"><p class="c2"><span class="c1">model = SGDClassifier(loss=&rsquo;log&rsquo;, penalty=&#39;l2&#39;, alpha=1e-3, random_state=RANDOM_SEED))</span></p></td></tr></tbody></table><h4 class="c3" id="h.wpirsbiqpcx1"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 377.00px; height: 126.00px;"><img alt="" src="images/image1.png" style="width: 377.00px; height: 126.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 224.64px; height: 200.22px;"><img alt="" src="images/image10.png" style="width: 224.64px; height: 200.22px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></h4><p class="c2"><span class="c9">0 is negative, 4 is positive</span></p><p class="c2"><span class="c1">SGD Classifier gave us the best recall for positive tweets, but the worst for negative tweets. The precision and f1-scores were on par with the rest. The size of these models were the smallest, but had the worst accuracy ceiling compared to the other models.</span></p><p class="c2 c6"><span class="c1"></span></p><p class="c2 c6"><span class="c1"></span></p><h4 class="c3" id="h.2h17rbe49mqu"><span class="c7">Linear Support Vector Classifier</span></h4><a id="t.7c431c50727ef89488c086ebe8ebd511a21fcf84"></a><a id="t.6"></a><table class="c26"><tbody><tr class="c27"><td class="c10" colspan="1" rowspan="1"><p class="c4"><span class="c1">model = CalibratedClassifierCV(base_estimator=LinearSVC(tol=1e-4,penalty=&#39;l2&#39;,dual=False,random_state=RANDOM_SEED),cv=5))</span></p></td></tr></tbody></table><p class="c2 c6"><span class="c1"></span></p><p class="c2"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 378.00px; height: 124.00px;"><img alt="" src="images/image15.png" style="width: 378.00px; height: 124.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 224.64px; height: 200.22px;"><img alt="" src="images/image4.png" style="width: 224.64px; height: 200.22px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c2"><span class="c9">0 is negative, 4 is positive</span></p><p class="c2"><span>We added CalibratedClassifierCV to this model, so that we would be able to get prediction probabilities into our model. LinearSVC was the best performing model we had. With more training data, the performance kept improving. Size was the limiting factor for this.</span></p><h4 class="c3" id="h.zfobancp27wa"><span class="c7">Results</span></h4><p class="c24 c31"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 501.00px; height: 347.00px;"><img alt="" src="images/image3.png" style="width: 501.00px; height: 347.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c2 c24"><span class="c1">A large part of this project was finding the balance between accuracy and pickle size. The size of the pickled model is important because we are hosting the model on Google Cloud and for each tweet, we&rsquo;re loading and running the model. If we have a large model, such as the SVC model with 79% accuracy and 600mb file size, then it will take several seconds to load the model, for each tweet, which would ruin the user experience of scrolling through Twitter. We came to the conclusion that around 10mb (10,000kb) would be the largest model that wouldn&rsquo;t interfere with the user experience. By using this graphic and that criteria, we decided to apply the SVC model that was around 9mb with an accuracy of 73% for the sentiment filtering.</span></p><h4 class="c3" id="h.lf1anxwzzgd5"><span class="c7">LinearSVC Model Performance on Human-Labeled Tweets</span></h4><p class="c2"><span class="c1">Though we viewed the Sentiment140 Dataset used for training as a sufficient option for model experimentation and training, we had some concerns that it was not a representative dataset for the current state of Twitter that our Chrome extension would be handling. Sentiment140 is fairly old (2009) and relied upon emoticons for classifying tweets as negative or positive, and the dataset itself strips out the emoticons that motivated labeling. Thus, within the dataset, there are likely instances where sentiment is misinterpreted by relying upon emoticons as the sole source of sentiment.</span></p><p class="c2 c6"><span class="c1"></span></p><p class="c2"><span class="c1">We therefore aimed to build another test set using a more recent batch of tweets that were human-labeled to assess whether our model performed similarly. The University of Michigan School of Information kindly provided us with several batches of randomized tweets collected from the Twitter API in October 2021. The tweets were processed to only English language tweets using the langdetect library, then given a preliminary sentiment label with the VADER algorithm in order to feed a similar amount of negative and positive/neutral tweets to our human labelers. 50 negative tweets (as determined by a VADER sentiment score of &gt;.7 negative) and 25 each of positive or neutral tweets (using the same VADER sentiment threshold as the negative tweets) were randomly selected from the English language tweets and uploaded to a Google Form for labeling.</span></p><p class="c2 c6"><span class="c1"></span></p><p class="c2"><span class="c1">After human labeling (n=14 labelers), the results of the survey were exported to a Google Sheet, then to a pandas dataframe for analysis; tweets were labeled negative or positive based on whether the majority of labelers picked each option. Examining the survey data revealed that there was significant disagreement between VADER and human labelers, with VADER being just 57% accurate when considering the human labelers as the ground truth. Perhaps unsurprisingly, there was also notable disagreement between the human labelers on what constitutes a negative or positive tweet, with just 8 of 100 tweets being labeled negative by all humans and 18 of 100 tweets being labeled as positive or neutral by all humans. With the variation in human labeling in mind, we analyzed the performance of the LinearSVC model (9 MB) used in production on the human-labeled tweets. The performance summary, confusion matrix, and ROC-AUC curves below show that the LinearSVC performs similarly on the human-labeled tweets to how it does on the Sentiment140 training and test data, with a small drop in accuracy (69.7% vs. 73.0%). Precision and recall are slightly lower in the Negative sentiment tweets, which could be a reflection of a change in how negativity is expressed currently compared to the training data, but it is also possible that with further human-labeled data we would see more similar performance, given that this is a small test set. An ROC generated with 100k of the training tweets has a similar shape and AUC to the plot generated with the human-labeled tweets, indicating similar performance between the two datasets.</span><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 333.50px; height: 158.24px;"><img alt="" src="images/image11.png" style="width: 333.50px; height: 158.24px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 308.45px; height: 237.50px;"><img alt="" src="images/image6.png" style="width: 308.45px; height: 237.50px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 334.00px; height: 229.00px;"><img alt="" src="images/image9.png" style="width: 334.00px; height: 229.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 316.14px; height: 229.00px;"><img alt="" src="images/image12.png" style="width: 316.14px; height: 229.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c2 c6"><span class="c1"></span></p><p class="c2"><span class="c1">Given the apparent disagreement between the human labelers on what constitutes a negative or positive tweet, we hypothesized that the total fraction of labelers who tagged a tweet positive/negative could be considered a probability of positivity/negativity in a similar way that the LinearSVC can output predicted probabilities for each class. Since the output of the predict_proba for the positive/neutral class is used in our slider, we examined the differences in our model&rsquo;s predicted probability and the probability designated by humans for both negative and positive/neutral tweets. We found that our model is generally more conservative with its estimates compared with the human labelers on the test set. </span></p><p class="c2 c6"><span class="c1"></span></p><p class="c2 c6"><span class="c1"></span></p><h3 class="c17 c19" id="h.603hngma5t0r"><span class="c5"></span></h3><h3 class="c17 c19" id="h.uts3jqpua5zk"><span class="c5"></span></h3><h3 class="c17" id="h.w8d59qk032ff"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 333.50px; height: 223.00px;"><img alt="" src="images/image5.png" style="width: 333.50px; height: 223.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 330.75px; height: 220.50px;"><img alt="" src="images/image2.png" style="width: 330.75px; height: 220.50px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></h3><h3 class="c17 c19" id="h.hhvpfyy7w9bi"><span class="c5"></span></h3><p class="c2 c6"><span class="c1"></span></p><p class="c2 c6"><span class="c1"></span></p><p class="c2 c6"><span class="c1"></span></p><p class="c2 c6"><span class="c1"></span></p><p class="c2 c6"><span class="c1"></span></p><p class="c2 c6"><span class="c1"></span></p><p class="c2 c6"><span class="c1"></span></p><p class="c2"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 331.00px; height: 221.00px;"><img alt="" src="images/image7.png" style="width: 331.00px; height: 221.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c2 c6"><span class="c1"></span></p><p class="c2 c6"><span class="c1"></span></p><p class="c2 c6"><span class="c1"></span></p><h3 class="c17 c19" id="h.6i6egm12t7ml"><span class="c5"></span></h3><h3 class="c17" id="h.ggstgwpv4s4m"><span class="c5">LDA</span></h3><p class="c2"><span>To handle the word filter aspect of the extension, we looked to apply Latent Dirichlet Allocation to add words of similar meaning to the filter.</span></p><h4 class="c3" id="h.bz0t0zbleixo"><span class="c7">Gensim</span></h4><p class="c2"><span class="c1">Our initial thought was to use Gensim. We created a dictionary of the tokens and then a corpus of the tweets as a bag of words. From there we trained a LDA model. This took an extremely long amount of time to run, and once it was finished running (even at only 10 topics), the topics were full of jumbled words and we felt that it wouldn&rsquo;t be very accurate. The file size was also large and it did not seem as if this would be the route to take to get this into the extension.</span></p><h4 class="c3" id="h.fwwvcuer5wyr"><span class="c7">Thesaurus</span></h4><p class="c2"><span>Since Gensim wasn&rsquo;t going to work for our particular application, we decided to take a different approach using a thesaurus. We found a thesaurus in JSON format with hundreds of thousands of words. We took that thesaurus and lemmatized it so that the format of the words in the JSON file would match the same format as if a word from a tweet was passed by it. How it works is that when a user adds a filter word to the extension, the extension adds all of the synonyms of that word behind the scenes to the filter. Then, when a tweet is loaded, all of the words are checked for the filter word(s) and their synonyms. If there are any hits, the extension blocks the tweet.</span></p><h2 class="c0" id="h.4dx90asel2g6"><span class="c12">What is negativity?</span></h2><p class="c2"><span class="c1">With the decision to filter negative posts out of a feed, we had to come to a consensus on what we mean by &ldquo;negative&rdquo;. </span></p><h2 class="c0" id="h.dscmy5708fgr"><span class="c12">Ethics of Removing Posts</span></h2><p class="c2"><span class="c1">When we came to the decision of removing posts from a user&rsquo;s feed, we had to take careful consideration of the ethics of the action. Since the model isn&rsquo;t perfect, there will be instances where it removes posts from the feed that aren&rsquo;t negative (and leave some that are). To alert users of this, we included a disclaimer in the readme that mentions the above.</span></p><h2 class="c0" id="h.2l3qeenkholf"><span class="c12">Conclusion</span></h2><p class="c2"><span>Github for Models: </span><span class="c8"><a class="c11" href="https://www.google.com/url?q=https://github.com/mphillipsjr96/SocialMedia_Content_Filter&amp;sa=D&amp;source=editors&amp;ust=1639840691562000&amp;usg=AOvVaw1Kzb4PwB3YKLWhyYz1TfFW">https://github.com/mphillipsjr96/SocialMedia_Content_Filter</a></span><span class="c1">&nbsp;</span></p><p class="c2"><span>Github for Extension: </span><span class="c8"><a class="c11" href="https://www.google.com/url?q=https://github.com/drkinder/content-filter-chrome-extension&amp;sa=D&amp;source=editors&amp;ust=1639840691562000&amp;usg=AOvVaw0k41Alj0NRfz84PEBJYw0l">https://github.com/drkinder/content-filter-chrome-extension</a></span><span class="c1">&nbsp;</span></p><h3 class="c17" id="h.8trqlcttcw1v"><span class="c5">Where to go from here</span></h3><p class="c2"><span class="c1">There are numerous ways we can advance this project in the future. This project can be expanded to other social media platforms, be more intuitive and learn from what the user wants hidden, as well as provide a way for the user to see what was hidden (if they wish). Also, there is always the opportunity for continuous improvement of the models. More robust topic modeling would be a starting point by trying to create an efficient model for topic filtering. This may be able to be accomplished by experimenting with different ways of chaining models together.</span></p></body></html>
