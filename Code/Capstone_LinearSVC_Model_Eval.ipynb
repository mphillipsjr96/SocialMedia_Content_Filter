{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import preprocessor as p\n",
    "import string\n",
    "import re\n",
    "import pickle as pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent140tweets = pd.read_csv('Desktop/full_tweets.csv', usecols = [0,5], names = ['label','tweet'], encoding = 'latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "responses = pd.read_csv('Downloads/MADS Tweet Sentiment Labeling (Responses) - Form Responses 1.csv').T.iloc[1:,:].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vader_labeled_tweets = pd.read_csv('Desktop/sampled_tweets.csv')\n",
    "vader_labeled_tweets['sentiment'] = vader_labeled_tweets['sentiment'].map({'negative':0,'neutral':4,'positive':4})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mapper(x):\n",
    "    if x == 'Negative':\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "responses.iloc[:,1:] = responses.iloc[:,1:].applymap(lambda x : mapper(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "responses['%neg'] = responses.iloc[:,1:].sum(axis=1)/14\n",
    "responses['%pos-neut'] = 1-responses['%neg']\n",
    "responses['label'] = np.round_(responses.iloc[:,1:].sum(axis=1)/14,0).astype(int)\n",
    "responses = responses[['index', 'label','%neg','%pos-neut']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_neg = responses[responses['%neg']==1].count()\n",
    "all_posneut = responses[responses['%pos-neut']==1].count()\n",
    "all_neg, all_posneut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "responses['index'] = responses['index'].str[3:]\n",
    "responses = responses.rename(columns={'index':'tweet'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "responses['label'] = responses['label'].map({1:0, 0:4})\n",
    "responses['vader_label'] = vader_labeled_tweets['sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "vader_acc = accuracy_score(responses['label'], responses['vader_label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "responses.groupby('label').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with open('/Users/ryanmaloney/Downloads/phrasemodel_SVC.sav', 'rb') as f:\n",
    "    phrase_model = pkl.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LSI preprocessing \n",
    "from gensim.parsing.preprocessing import preprocess_string, STOPWORDS\n",
    "CUSTOM_STOP_WORDS = ['www','twitpic','tinyurl','com', 'https', 'http', '&amp', 'rt', 'bit', 'ly', 'bitly']\n",
    "FULL_STOP = STOPWORDS.union(set(CUSTOM_STOP_WORDS))\n",
    "\n",
    "def preprocess_tweet_body(path, tweet_body):\n",
    "    \"\"\"Converts a single Tweet text into a list of bigrams for classification.\n",
    "\n",
    "    :param path: the path to the pickled phrase model\n",
    "    :param tweet_body: the text content of a single Tweet\n",
    "    :return: List[str] underscores between bigrams in single str\n",
    "    \"\"\"\n",
    "    phrase_model = pkl.load(open(path, 'rb'))\n",
    "    tweet_tokens = preprocess_string(tweet_body)\n",
    "    tweet_tokens = [word for word in tweet_tokens if word not in FULL_STOP]\n",
    "    return phrase_model[tweet_tokens]\n",
    "\n",
    "tweets = responses['tweet']\n",
    "tweets = tweets.apply(lambda x : preprocess_tweet_body('/Users/ryanmaloney/Downloads/phrasemodel_SVC.sav', x))\n",
    "labeled_tweets = sent140tweets['tweet']\n",
    "labeled_tweets = labeled_tweets.apply(lambda x : preprocess_tweet_body('/Users/ryanmaloney/Downloads/phrasemodel_SVC.sav', x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with open('/Users/ryanmaloney/Desktop/LinearSVCModel.sav', 'rb') as f:\n",
    "    SVC_model = pkl.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "SVC_preds = []\n",
    "SVC_pred_neg = []\n",
    "SVC_pred_posneut = []\n",
    "for tokens in tweets:\n",
    "    tweet = [\" \".join(tokens)]\n",
    "    pred = SVC_model.predict(tweet)\n",
    "    probas = SVC_model.predict_proba(tweet)[0]\n",
    "    SVC_pred_neg.append(probas[0])\n",
    "    SVC_pred_posneut.append(probas[1])\n",
    "    SVC_preds.append(pred[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "responses['SVC_preds'] = SVC_preds\n",
    "responses['SVC_pred_neg'] = SVC_pred_neg\n",
    "responses['SVC_pred_posneut'] = SVC_pred_posneut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_sent140 = sent140_tweets.sample(n=100000,random_state=42).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_training = []\n",
    "pred_proba_training_neg = []\n",
    "pred_proba_training_posneut = []\n",
    "for tokens in tqdm(sampled_sent140['tokenized_tweets'].values):\n",
    "    tweet = [\" \".join(tokens)]\n",
    "    pred = SVC_model.predict(tweet)\n",
    "    probas = SVC_model.predict_proba(tweet)[0]\n",
    "    pred_proba_training_neg.append(probas[0])\n",
    "    pred_proba_training_posneut.append(probas[1])\n",
    "    pred_training.append(pred[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_preds_df = pd.DataFrame()\n",
    "training_preds_df['Negative_Probability'] = pred_proba_training_neg\n",
    "training_preds_df['PositiveNeutral_Probability'] = pred_proba_training_posneut\n",
    "training_preds_df['Prediction'] = pred_training\n",
    "training_preds_df['True_Label'] = sampled_sent140['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hu_labeled_report = classification_report(responses['label'],responses['SVC_preds'], output_dict=True)\n",
    "hu_labeled_report_df = pd.DataFrame(hu_labeled_report).T\n",
    "hu_labeled_report_df = hu_labeled_report_df.rename(index={'0':'Negative (0)', '4':'Postive/Neutral (4)'})\n",
    "hu_labeled_report_df[['precision','recall','f1-score']] = hu_labeled_report_df[['precision','recall','f1-score']]*100\n",
    "hu_labeled_report_df = hu_labeled_report_df.round(1)\n",
    "hu_labeled_report_df.iloc[2,:2] = ''\n",
    "hu_labeled_report_df.iloc[2,3] = ''\n",
    "\n",
    "hu_labeled_report_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Confusion Matrix, Human-Labeled Data\n",
    "confusion_mat = confusion_matrix(responses['label'],responses['SVC_preds'])\n",
    "fig, ax = plt.subplots(figsize=(4,4))\n",
    "sns.heatmap(confusion_mat,annot=True,fmt='g',\n",
    "            ax=ax,xticklabels=['Negative','Positive'],yticklabels=['Negative','Positive'])\n",
    "ax.set_title('Confusion Matrix, LinearSVC on Human-Labeled Tweets')\n",
    "plt.savefig('Desktop/Capstone_Figs/human_labeled_confusionmatrix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, thresh = roc_curve(responses['label'], responses['SVC_pred_posneut'], pos_label=4)\n",
    "roc_auc_hu_tweets = auc(fpr, tpr)\n",
    "roc_auc_hu_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fig, ax = plt.subplots()\n",
    "#sns.lineplot(x=fpr,y=tpr, color='navy')\n",
    "plt.plot(fpr, tpr, color='firebrick')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve - AUC 79.6% (Linear SVC on Human-Labeled Tweets)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr_training, tpr_training, thresh = roc_curve(training_preds_df['True_Label'], training_preds_df['PositiveNeutral_Probability'], pos_label=4)\n",
    "roc_auc_training_tweets = auc(fpr_training, tpr_training)\n",
    "roc_auc_training_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(fpr_training, tpr_training, color='navy')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve - AUC 72.8% (Linear SVC on Training Tweets)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "responses['Positive/Neutral Prediction Difference'] = responses['%pos-neut']-responses['SVC_pred_posneut']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "neg_only = responses[responses['label']==0]\n",
    "pos_only = responses[responses['label']==4]\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "sns.set(rc={\"figure.figsize\":(10, 10)})\n",
    "sns.set_theme(style=\"white\", palette=None)\n",
    "\n",
    "neg_palette = neg_only['Positive/Neutral Prediction Difference'].apply(lambda x : 'navy' if x > 0 else 'firebrick').values\n",
    "neg_bar = sns.barplot(x=neg_only.index.values, y='Positive/Neutral Prediction Difference', data=neg_only, palette = neg_palette,\n",
    "                     ax=ax)\n",
    "ax.set_ylabel('<-Human Labeled More Negative             Human Labeled Less Negative->', size=14)\n",
    "ax.get_xaxis().set_ticks([])\n",
    "ax.set_title('Positive Probability Difference Between Human Labeling and SVC, Negative Tweets', size=14)\n",
    "plt.savefig('Desktop/Capstone_Figs/barplot_neg.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "pos_palette = pos_only['Positive/Neutral Prediction Difference'].apply(lambda x : 'navy' if x > 0 else 'firebrick').values\n",
    "sns.set(rc={\"figure.figsize\":(10, 10)})\n",
    "sns.set_theme(style=\"white\", palette=None)\n",
    "\n",
    "\n",
    "sns.barplot(x=pos_only.index.values, y='Positive/Neutral Prediction Difference', data=pos_only, palette = pos_palette)\n",
    "ax.set_title('Positive Probability Difference Between Human Labeling and SVC, Positive Tweets', size=14)\n",
    "ax.set_ylabel('<-Human Labeled Less Positive             Human Labeled More Positivee->', size =14)\n",
    "ax.get_xaxis().set_ticks([])\n",
    "plt.savefig('Desktop/Capstone_Figs/barplot_pos.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "sns.set(rc={\"figure.figsize\":(9, 7)})\n",
    "sns.set_theme(style=\"white\", palette=None)\n",
    "sns.kdeplot(data=training_preds_df, x='PositiveNeutral_Probability',\n",
    "            fill=True, alpha=.2, bw_adjust=.5, color='navy', ax=ax).set(\n",
    "    title='Positive/Neutral Prediction Distribution, Training Tweets')\n",
    "ax.set_xticks([0,.1,.2,.3,.4,.5,.6,.7,.8,.9,1.0])\n",
    "ax.set_xticklabels([0,.1,.2,.3,.4,.5,.6,.7,.8,.9,1.0])\n",
    "ax.set_xlabel('Positive or Neutral Probability')\n",
    "plt.savefig('Desktop/Capstone_Figs/pos_prob_trainingtweets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_preds_neg = training_preds_df[training_preds_df['True_Label']==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "sns.kdeplot(data=training_preds_neg, x='PositiveNeutral_Probability',\n",
    "            fill=True, alpha=.2, bw_adjust=.5, color='navy',ax=ax).set(\n",
    "    title='Positive/Neutral Prediction Distribution, Training Negatives')\n",
    "ax.set_xticks([0,.1,.2,.3,.4,.5,.6,.7,.8,.9,1.0])\n",
    "ax.set_xticklabels([0,.1,.2,.3,.4,.5,.6,.7,.8,.9,1.0])\n",
    "ax.set_xlabel('Positive or Neutral Probability')\n",
    "plt.savefig('Desktop/Capstone_Figs/Pos_predicted_training_negs.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "responses_neg = responses[responses['label']==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "sns.kdeplot(data=responses, x='SVC_pred_posneut',\n",
    "            fill=True, alpha=.2, bw_adjust=.5, color='firebrick',ax=ax).set(\n",
    "    title='Positive Prediction Distribution, Human-Labeled Tweets')\n",
    "ax.set_xticks([0,.1,.2,.3,.4,.5,.6,.7,.8,.9,1.0])\n",
    "ax.set_xticklabels([0,.1,.2,.3,.4,.5,.6,.7,.8,.9,1.0])\n",
    "ax.set_xlabel('Positive or Neutral Probability')\n",
    "plt.savefig('Desktop/Capstone_Figs/Pos_predicted_prob_human_labeled.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "sns.kdeplot(data=responses_neg, x='SVC_pred_posneut',\n",
    "            fill=True, alpha=.2, bw_adjust=.5, color='firebrick', ax=ax).set(\n",
    "    title='Positive/Neutral Prediction Distribution, Human-Labeled Negatives')\n",
    "ax.set_xticks([0,.1,.2,.3,.4,.5,.6,.7,.8,.9,1.0])\n",
    "ax.set_xticklabels([0,.1,.2,.3,.4,.5,.6,.7,.8,.9,1.0])\n",
    "ax.set_xlabel('Positive or Neutral Probability')\n",
    "plt.savefig('Desktop/Capstone_Figs/Pos_predicted_prob_human_labeled_negs.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
