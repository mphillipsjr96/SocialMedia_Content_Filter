<html>
<style>
    body {
        background-color: #F8F9FA;
        padding-top: 20px;
    }
    div.center-column {
        background-color: #FFFFFF;
        margin: auto;
        width: 100%;
        border: 2px solid darkgray;
        padding: 20px 30px 20px 30px;
    }
    body.img {
        margin: auto !important;
    }
</style>
<!-- NOTE: AFTER UPDATING BODY, MUST WRAP ALL INSIDE DIV WITH CLASS="center-column" -->

<div class='center-column'>
<head><meta content="text/html; charset=UTF-8" http-equiv="content-type"><style type="text/css">.lst-kix_vp08mferwxv9-5>li:before{content:"\0025a0  "}.lst-kix_vp08mferwxv9-3>li:before{content:"\0025cf  "}.lst-kix_vp08mferwxv9-7>li:before{content:"\0025cb  "}.lst-kix_vp08mferwxv9-2>li:before{content:"\0025a0  "}.lst-kix_vp08mferwxv9-6>li:before{content:"\0025cf  "}.lst-kix_d6hbfom0mitp-0>li:before{content:"" counter(lst-ctn-kix_d6hbfom0mitp-0,decimal) ") "}.lst-kix_vp08mferwxv9-1>li:before{content:"\0025cb  "}ol.lst-kix_1aefkzsvu2l5-8.start{counter-reset:lst-ctn-kix_1aefkzsvu2l5-8 0}.lst-kix_d6hbfom0mitp-1>li:before{content:"" counter(lst-ctn-kix_d6hbfom0mitp-1,lower-latin) ") "}.lst-kix_1aefkzsvu2l5-0>li{counter-increment:lst-ctn-kix_1aefkzsvu2l5-0}.lst-kix_d6hbfom0mitp-3>li:before{content:"(" counter(lst-ctn-kix_d6hbfom0mitp-3,decimal) ") "}ol.lst-kix_bj4jmq89m33u-7.start{counter-reset:lst-ctn-kix_bj4jmq89m33u-7 0}.lst-kix_vp08mferwxv9-0>li:before{content:"\0025cf  "}.lst-kix_vp08mferwxv9-8>li:before{content:"\0025a0  "}.lst-kix_d6hbfom0mitp-2>li:before{content:"" counter(lst-ctn-kix_d6hbfom0mitp-2,lower-roman) ") "}.lst-kix_bj4jmq89m33u-4>li{counter-increment:lst-ctn-kix_bj4jmq89m33u-4}.lst-kix_d6hbfom0mitp-5>li:before{content:"(" counter(lst-ctn-kix_d6hbfom0mitp-5,lower-roman) ") "}.lst-kix_d6hbfom0mitp-3>li{counter-increment:lst-ctn-kix_d6hbfom0mitp-3}.lst-kix_d6hbfom0mitp-4>li:before{content:"(" counter(lst-ctn-kix_d6hbfom0mitp-4,lower-latin) ") "}.lst-kix_d6hbfom0mitp-8>li:before{content:"" counter(lst-ctn-kix_d6hbfom0mitp-8,lower-roman) ". "}.lst-kix_d6hbfom0mitp-7>li:before{content:"" counter(lst-ctn-kix_d6hbfom0mitp-7,lower-latin) ". "}.lst-kix_d6hbfom0mitp-6>li:before{content:"" counter(lst-ctn-kix_d6hbfom0mitp-6,decimal) ". "}.lst-kix_bj4jmq89m33u-6>li{counter-increment:lst-ctn-kix_bj4jmq89m33u-6}ul.lst-kix_pgcx5w8qf1x6-0{list-style-type:none}ol.lst-kix_d6hbfom0mitp-1.start{counter-reset:lst-ctn-kix_d6hbfom0mitp-1 0}ul.lst-kix_yqt5lwbtzcl-8{list-style-type:none}ul.lst-kix_pgcx5w8qf1x6-6{list-style-type:none}ul.lst-kix_pgcx5w8qf1x6-5{list-style-type:none}ol.lst-kix_d6hbfom0mitp-7.start{counter-reset:lst-ctn-kix_d6hbfom0mitp-7 0}ul.lst-kix_pgcx5w8qf1x6-8{list-style-type:none}ul.lst-kix_pgcx5w8qf1x6-7{list-style-type:none}ul.lst-kix_yqt5lwbtzcl-4{list-style-type:none}ul.lst-kix_pgcx5w8qf1x6-2{list-style-type:none}ul.lst-kix_yqt5lwbtzcl-5{list-style-type:none}ul.lst-kix_pgcx5w8qf1x6-1{list-style-type:none}ul.lst-kix_yqt5lwbtzcl-6{list-style-type:none}ul.lst-kix_pgcx5w8qf1x6-4{list-style-type:none}ul.lst-kix_yqt5lwbtzcl-7{list-style-type:none}ul.lst-kix_pgcx5w8qf1x6-3{list-style-type:none}ul.lst-kix_yqt5lwbtzcl-0{list-style-type:none}ul.lst-kix_yqt5lwbtzcl-1{list-style-type:none}ul.lst-kix_yqt5lwbtzcl-2{list-style-type:none}ul.lst-kix_yqt5lwbtzcl-3{list-style-type:none}.lst-kix_vp08mferwxv9-4>li:before{content:"\0025cb  "}.lst-kix_d6hbfom0mitp-1>li{counter-increment:lst-ctn-kix_d6hbfom0mitp-1}.lst-kix_1aefkzsvu2l5-0>li:before{content:"" counter(lst-ctn-kix_1aefkzsvu2l5-0,decimal) ") "}.lst-kix_d6hbfom0mitp-7>li{counter-increment:lst-ctn-kix_d6hbfom0mitp-7}.lst-kix_1aefkzsvu2l5-1>li:before{content:"" counter(lst-ctn-kix_1aefkzsvu2l5-1,lower-latin) ") "}ol.lst-kix_d6hbfom0mitp-2.start{counter-reset:lst-ctn-kix_d6hbfom0mitp-2 0}.lst-kix_1aefkzsvu2l5-7>li:before{content:"" counter(lst-ctn-kix_1aefkzsvu2l5-7,lower-latin) ". "}.lst-kix_1aefkzsvu2l5-8>li:before{content:"" counter(lst-ctn-kix_1aefkzsvu2l5-8,lower-roman) ". "}ul.lst-kix_5trkhh7gtywe-6{list-style-type:none}ul.lst-kix_5trkhh7gtywe-7{list-style-type:none}ul.lst-kix_5trkhh7gtywe-8{list-style-type:none}ul.lst-kix_vp08mferwxv9-1{list-style-type:none}.lst-kix_1aefkzsvu2l5-4>li{counter-increment:lst-ctn-kix_1aefkzsvu2l5-4}ul.lst-kix_vp08mferwxv9-2{list-style-type:none}ul.lst-kix_vp08mferwxv9-3{list-style-type:none}.lst-kix_1aefkzsvu2l5-7>li{counter-increment:lst-ctn-kix_1aefkzsvu2l5-7}ul.lst-kix_vp08mferwxv9-4{list-style-type:none}ul.lst-kix_vp08mferwxv9-0{list-style-type:none}ul.lst-kix_5trkhh7gtywe-2{list-style-type:none}ul.lst-kix_5trkhh7gtywe-3{list-style-type:none}ul.lst-kix_5trkhh7gtywe-4{list-style-type:none}ul.lst-kix_5trkhh7gtywe-5{list-style-type:none}ul.lst-kix_5trkhh7gtywe-0{list-style-type:none}ul.lst-kix_5trkhh7gtywe-1{list-style-type:none}ul.lst-kix_r92oh920e7v5-8{list-style-type:none}ul.lst-kix_r92oh920e7v5-7{list-style-type:none}ul.lst-kix_r92oh920e7v5-6{list-style-type:none}.lst-kix_1aefkzsvu2l5-6>li:before{content:"" counter(lst-ctn-kix_1aefkzsvu2l5-6,decimal) ". "}ul.lst-kix_r92oh920e7v5-5{list-style-type:none}.lst-kix_1aefkzsvu2l5-5>li:before{content:"(" counter(lst-ctn-kix_1aefkzsvu2l5-5,lower-roman) ") "}.lst-kix_bj4jmq89m33u-2>li{counter-increment:lst-ctn-kix_bj4jmq89m33u-2}ul.lst-kix_r92oh920e7v5-0{list-style-type:none}.lst-kix_1aefkzsvu2l5-2>li:before{content:"" counter(lst-ctn-kix_1aefkzsvu2l5-2,lower-roman) ") "}.lst-kix_1aefkzsvu2l5-4>li:before{content:"(" counter(lst-ctn-kix_1aefkzsvu2l5-4,lower-latin) ") "}ul.lst-kix_vp08mferwxv9-5{list-style-type:none}ul.lst-kix_r92oh920e7v5-4{list-style-type:none}ul.lst-kix_vp08mferwxv9-6{list-style-type:none}ul.lst-kix_r92oh920e7v5-3{list-style-type:none}ul.lst-kix_vp08mferwxv9-7{list-style-type:none}.lst-kix_bj4jmq89m33u-8>li{counter-increment:lst-ctn-kix_bj4jmq89m33u-8}ul.lst-kix_r92oh920e7v5-2{list-style-type:none}ul.lst-kix_vp08mferwxv9-8{list-style-type:none}.lst-kix_1aefkzsvu2l5-3>li:before{content:"(" counter(lst-ctn-kix_1aefkzsvu2l5-3,decimal) ") "}ul.lst-kix_r92oh920e7v5-1{list-style-type:none}.lst-kix_jrgvomkt7wgu-5>li:before{content:"\0025a0  "}.lst-kix_jrgvomkt7wgu-2>li:before{content:"\0025a0  "}.lst-kix_jrgvomkt7wgu-0>li:before{content:"\0025cf  "}.lst-kix_jrgvomkt7wgu-7>li:before{content:"\0025cb  "}.lst-kix_1aefkzsvu2l5-5>li{counter-increment:lst-ctn-kix_1aefkzsvu2l5-5}.lst-kix_pgcx5w8qf1x6-0>li:before{content:"-  "}.lst-kix_5trkhh7gtywe-3>li:before{content:"-  "}.lst-kix_pgcx5w8qf1x6-2>li:before{content:"-  "}.lst-kix_bj4jmq89m33u-6>li:before{content:"" counter(lst-ctn-kix_bj4jmq89m33u-6,decimal) ". "}.lst-kix_5trkhh7gtywe-5>li:before{content:"-  "}ol.lst-kix_d6hbfom0mitp-8.start{counter-reset:lst-ctn-kix_d6hbfom0mitp-8 0}.lst-kix_pgcx5w8qf1x6-6>li:before{content:"-  "}ol.lst-kix_bj4jmq89m33u-8.start{counter-reset:lst-ctn-kix_bj4jmq89m33u-8 0}.lst-kix_bj4jmq89m33u-8>li:before{content:"" counter(lst-ctn-kix_bj4jmq89m33u-8,lower-roman) ". "}.lst-kix_pgcx5w8qf1x6-4>li:before{content:"-  "}.lst-kix_5trkhh7gtywe-7>li:before{content:"-  "}.lst-kix_r92oh920e7v5-7>li:before{content:"\0025cb  "}.lst-kix_ogj0id8mrzjk-8>li:before{content:"\0025a0  "}ol.lst-kix_1aefkzsvu2l5-7.start{counter-reset:lst-ctn-kix_1aefkzsvu2l5-7 0}.lst-kix_pgcx5w8qf1x6-8>li:before{content:"-  "}ol.lst-kix_bj4jmq89m33u-6.start{counter-reset:lst-ctn-kix_bj4jmq89m33u-6 0}.lst-kix_r92oh920e7v5-3>li:before{content:"\0025cf  "}.lst-kix_r92oh920e7v5-5>li:before{content:"\0025a0  "}.lst-kix_bj4jmq89m33u-4>li:before{content:"" counter(lst-ctn-kix_bj4jmq89m33u-4,lower-latin) ". "}.lst-kix_5trkhh7gtywe-1>li:before{content:"-  "}.lst-kix_bj4jmq89m33u-0>li:before{content:"" counter(lst-ctn-kix_bj4jmq89m33u-0,decimal) ". "}.lst-kix_bj4jmq89m33u-2>li:before{content:"" counter(lst-ctn-kix_bj4jmq89m33u-2,lower-roman) ". "}.lst-kix_1aefkzsvu2l5-6>li{counter-increment:lst-ctn-kix_1aefkzsvu2l5-6}.lst-kix_r92oh920e7v5-1>li:before{content:"\0025cb  "}.lst-kix_prbiw0ezw3h8-8>li:before{content:"\0025a0  "}ol.lst-kix_d6hbfom0mitp-6.start{counter-reset:lst-ctn-kix_d6hbfom0mitp-6 0}ol.lst-kix_1aefkzsvu2l5-6{list-style-type:none}ol.lst-kix_1aefkzsvu2l5-7{list-style-type:none}ol.lst-kix_1aefkzsvu2l5-8{list-style-type:none}ol.lst-kix_1aefkzsvu2l5-2{list-style-type:none}ol.lst-kix_1aefkzsvu2l5-3{list-style-type:none}.lst-kix_prbiw0ezw3h8-6>li:before{content:"\0025cf  "}ol.lst-kix_1aefkzsvu2l5-4{list-style-type:none}ol.lst-kix_1aefkzsvu2l5-5{list-style-type:none}ol.lst-kix_1aefkzsvu2l5-0{list-style-type:none}ol.lst-kix_1aefkzsvu2l5-1{list-style-type:none}.lst-kix_prbiw0ezw3h8-0>li:before{content:"\0025cf  "}.lst-kix_prbiw0ezw3h8-2>li:before{content:"\0025a0  "}ul.lst-kix_jrgvomkt7wgu-7{list-style-type:none}ol.lst-kix_d6hbfom0mitp-7{list-style-type:none}ul.lst-kix_jrgvomkt7wgu-8{list-style-type:none}ol.lst-kix_d6hbfom0mitp-8{list-style-type:none}ul.lst-kix_jrgvomkt7wgu-5{list-style-type:none}ul.lst-kix_jrgvomkt7wgu-6{list-style-type:none}ol.lst-kix_d6hbfom0mitp-5.start{counter-reset:lst-ctn-kix_d6hbfom0mitp-5 0}.lst-kix_prbiw0ezw3h8-4>li:before{content:"\0025cb  "}ol.lst-kix_bj4jmq89m33u-1{list-style-type:none}ol.lst-kix_bj4jmq89m33u-0{list-style-type:none}ol.lst-kix_bj4jmq89m33u-3{list-style-type:none}ol.lst-kix_bj4jmq89m33u-2{list-style-type:none}ul.lst-kix_jrgvomkt7wgu-3{list-style-type:none}ol.lst-kix_d6hbfom0mitp-3{list-style-type:none}.lst-kix_d6hbfom0mitp-5>li{counter-increment:lst-ctn-kix_d6hbfom0mitp-5}ul.lst-kix_jrgvomkt7wgu-4{list-style-type:none}ol.lst-kix_d6hbfom0mitp-4{list-style-type:none}ol.lst-kix_bj4jmq89m33u-8{list-style-type:none}ul.lst-kix_jrgvomkt7wgu-1{list-style-type:none}ol.lst-kix_d6hbfom0mitp-5{list-style-type:none}ul.lst-kix_jrgvomkt7wgu-2{list-style-type:none}ol.lst-kix_d6hbfom0mitp-6{list-style-type:none}ol.lst-kix_bj4jmq89m33u-5{list-style-type:none}ul.lst-kix_jrgvomkt7wgu-0{list-style-type:none}ol.lst-kix_d6hbfom0mitp-0{list-style-type:none}ol.lst-kix_bj4jmq89m33u-4{list-style-type:none}ol.lst-kix_d6hbfom0mitp-1{list-style-type:none}ol.lst-kix_bj4jmq89m33u-7{list-style-type:none}ol.lst-kix_d6hbfom0mitp-2{list-style-type:none}ol.lst-kix_bj4jmq89m33u-6{list-style-type:none}ol.lst-kix_d6hbfom0mitp-4.start{counter-reset:lst-ctn-kix_d6hbfom0mitp-4 0}.lst-kix_d6hbfom0mitp-4>li{counter-increment:lst-ctn-kix_d6hbfom0mitp-4}ul.lst-kix_prbiw0ezw3h8-4{list-style-type:none}ul.lst-kix_prbiw0ezw3h8-5{list-style-type:none}ul.lst-kix_prbiw0ezw3h8-2{list-style-type:none}ul.lst-kix_prbiw0ezw3h8-3{list-style-type:none}ul.lst-kix_prbiw0ezw3h8-0{list-style-type:none}.lst-kix_bj4jmq89m33u-3>li{counter-increment:lst-ctn-kix_bj4jmq89m33u-3}ul.lst-kix_prbiw0ezw3h8-1{list-style-type:none}ul.lst-kix_prbiw0ezw3h8-8{list-style-type:none}ul.lst-kix_prbiw0ezw3h8-6{list-style-type:none}ul.lst-kix_prbiw0ezw3h8-7{list-style-type:none}ol.lst-kix_1aefkzsvu2l5-0.start{counter-reset:lst-ctn-kix_1aefkzsvu2l5-0 0}.lst-kix_ogj0id8mrzjk-1>li:before{content:"\0025cb  "}.lst-kix_ogj0id8mrzjk-0>li:before{content:"\0025cf  "}.lst-kix_ogj0id8mrzjk-6>li:before{content:"\0025cf  "}.lst-kix_d6hbfom0mitp-6>li{counter-increment:lst-ctn-kix_d6hbfom0mitp-6}.lst-kix_ogj0id8mrzjk-5>li:before{content:"\0025a0  "}ol.lst-kix_1aefkzsvu2l5-6.start{counter-reset:lst-ctn-kix_1aefkzsvu2l5-6 0}.lst-kix_ogj0id8mrzjk-2>li:before{content:"\0025a0  "}ol.lst-kix_bj4jmq89m33u-5.start{counter-reset:lst-ctn-kix_bj4jmq89m33u-5 0}.lst-kix_ogj0id8mrzjk-4>li:before{content:"\0025cb  "}.lst-kix_d6hbfom0mitp-0>li{counter-increment:lst-ctn-kix_d6hbfom0mitp-0}ol.lst-kix_d6hbfom0mitp-3.start{counter-reset:lst-ctn-kix_d6hbfom0mitp-3 0}.lst-kix_ogj0id8mrzjk-3>li:before{content:"\0025cf  "}.lst-kix_1aefkzsvu2l5-1>li{counter-increment:lst-ctn-kix_1aefkzsvu2l5-1}.lst-kix_yqt5lwbtzcl-8>li:before{content:"\0025a0  "}.lst-kix_yqt5lwbtzcl-7>li:before{content:"\0025cb  "}.lst-kix_yqt5lwbtzcl-6>li:before{content:"\0025cf  "}.lst-kix_yqt5lwbtzcl-5>li:before{content:"\0025a0  "}ul.lst-kix_ogj0id8mrzjk-1{list-style-type:none}.lst-kix_yqt5lwbtzcl-2>li:before{content:"\0025a0  "}.lst-kix_bj4jmq89m33u-5>li{counter-increment:lst-ctn-kix_bj4jmq89m33u-5}ul.lst-kix_ogj0id8mrzjk-0{list-style-type:none}.lst-kix_yqt5lwbtzcl-0>li:before{content:"\0025cf  "}.lst-kix_yqt5lwbtzcl-4>li:before{content:"\0025cb  "}.lst-kix_yqt5lwbtzcl-3>li:before{content:"\0025cf  "}ul.lst-kix_ogj0id8mrzjk-8{list-style-type:none}ul.lst-kix_ogj0id8mrzjk-7{list-style-type:none}ul.lst-kix_ogj0id8mrzjk-6{list-style-type:none}ul.lst-kix_ogj0id8mrzjk-5{list-style-type:none}ol.lst-kix_bj4jmq89m33u-4.start{counter-reset:lst-ctn-kix_bj4jmq89m33u-4 0}ul.lst-kix_ogj0id8mrzjk-4{list-style-type:none}ul.lst-kix_ogj0id8mrzjk-3{list-style-type:none}.lst-kix_yqt5lwbtzcl-1>li:before{content:"\0025cb  "}ul.lst-kix_ogj0id8mrzjk-2{list-style-type:none}ol.lst-kix_1aefkzsvu2l5-5.start{counter-reset:lst-ctn-kix_1aefkzsvu2l5-5 0}.lst-kix_jrgvomkt7wgu-4>li:before{content:"\0025cb  "}.lst-kix_jrgvomkt7wgu-3>li:before{content:"\0025cf  "}.lst-kix_5trkhh7gtywe-8>li:before{content:"-  "}.lst-kix_jrgvomkt7wgu-6>li:before{content:"\0025cf  "}.lst-kix_jrgvomkt7wgu-8>li:before{content:"\0025a0  "}.lst-kix_jrgvomkt7wgu-1>li:before{content:"\0025cb  "}.lst-kix_5trkhh7gtywe-4>li:before{content:"-  "}.lst-kix_pgcx5w8qf1x6-1>li:before{content:"-  "}.lst-kix_bj4jmq89m33u-5>li:before{content:"" counter(lst-ctn-kix_bj4jmq89m33u-5,lower-roman) ". "}ol.lst-kix_d6hbfom0mitp-0.start{counter-reset:lst-ctn-kix_d6hbfom0mitp-0 0}.lst-kix_pgcx5w8qf1x6-3>li:before{content:"-  "}.lst-kix_bj4jmq89m33u-7>li:before{content:"" counter(lst-ctn-kix_bj4jmq89m33u-7,lower-latin) ". "}.lst-kix_5trkhh7gtywe-6>li:before{content:"-  "}ol.lst-kix_1aefkzsvu2l5-1.start{counter-reset:lst-ctn-kix_1aefkzsvu2l5-1 0}.lst-kix_pgcx5w8qf1x6-5>li:before{content:"-  "}ol.lst-kix_bj4jmq89m33u-0.start{counter-reset:lst-ctn-kix_bj4jmq89m33u-0 0}ol.lst-kix_bj4jmq89m33u-3.start{counter-reset:lst-ctn-kix_bj4jmq89m33u-3 0}.lst-kix_pgcx5w8qf1x6-7>li:before{content:"-  "}ol.lst-kix_1aefkzsvu2l5-4.start{counter-reset:lst-ctn-kix_1aefkzsvu2l5-4 0}.lst-kix_r92oh920e7v5-8>li:before{content:"\0025a0  "}.lst-kix_ogj0id8mrzjk-7>li:before{content:"\0025cb  "}.lst-kix_r92oh920e7v5-4>li:before{content:"\0025cb  "}.lst-kix_5trkhh7gtywe-0>li:before{content:"-  "}.lst-kix_5trkhh7gtywe-2>li:before{content:"-  "}.lst-kix_r92oh920e7v5-2>li:before{content:"\0025a0  "}.lst-kix_r92oh920e7v5-6>li:before{content:"\0025cf  "}.lst-kix_1aefkzsvu2l5-3>li{counter-increment:lst-ctn-kix_1aefkzsvu2l5-3}.lst-kix_bj4jmq89m33u-3>li:before{content:"" counter(lst-ctn-kix_bj4jmq89m33u-3,decimal) ". "}.lst-kix_bj4jmq89m33u-1>li:before{content:"" counter(lst-ctn-kix_bj4jmq89m33u-1,lower-latin) ". "}.lst-kix_bj4jmq89m33u-7>li{counter-increment:lst-ctn-kix_bj4jmq89m33u-7}.lst-kix_1aefkzsvu2l5-8>li{counter-increment:lst-ctn-kix_1aefkzsvu2l5-8}.lst-kix_bj4jmq89m33u-1>li{counter-increment:lst-ctn-kix_bj4jmq89m33u-1}.lst-kix_1aefkzsvu2l5-2>li{counter-increment:lst-ctn-kix_1aefkzsvu2l5-2}ol.lst-kix_1aefkzsvu2l5-3.start{counter-reset:lst-ctn-kix_1aefkzsvu2l5-3 0}ol.lst-kix_bj4jmq89m33u-2.start{counter-reset:lst-ctn-kix_bj4jmq89m33u-2 0}.lst-kix_r92oh920e7v5-0>li:before{content:"\0025cf  "}.lst-kix_prbiw0ezw3h8-5>li:before{content:"\0025a0  "}.lst-kix_prbiw0ezw3h8-7>li:before{content:"\0025cb  "}.lst-kix_bj4jmq89m33u-0>li{counter-increment:lst-ctn-kix_bj4jmq89m33u-0}.lst-kix_prbiw0ezw3h8-1>li:before{content:"\0025cb  "}ol.lst-kix_1aefkzsvu2l5-2.start{counter-reset:lst-ctn-kix_1aefkzsvu2l5-2 0}.lst-kix_prbiw0ezw3h8-3>li:before{content:"\0025cf  "}li.li-bullet-0:before{margin-left:-18pt;white-space:nowrap;display:inline-block;min-width:18pt}ol.lst-kix_bj4jmq89m33u-1.start{counter-reset:lst-ctn-kix_bj4jmq89m33u-1 0}.lst-kix_d6hbfom0mitp-2>li{counter-increment:lst-ctn-kix_d6hbfom0mitp-2}.lst-kix_d6hbfom0mitp-8>li{counter-increment:lst-ctn-kix_d6hbfom0mitp-8}ol{margin:0;padding:0}table td,table th{padding:0}.c9{border-right-style:solid;padding:5pt 5pt 5pt 5pt;border-bottom-color:#000000;border-top-width:1pt;border-right-width:1pt;border-left-color:#000000;vertical-align:top;border-right-color:#000000;border-left-width:1pt;border-top-style:solid;border-left-style:solid;border-bottom-width:1pt;width:57.8pt;border-top-color:#000000;border-bottom-style:solid}.c6{border-right-style:solid;padding:5pt 5pt 5pt 5pt;border-bottom-color:#000000;border-top-width:1pt;border-right-width:1pt;border-left-color:#000000;vertical-align:top;border-right-color:#000000;border-left-width:1pt;border-top-style:solid;border-left-style:solid;border-bottom-width:1pt;width:56.2pt;border-top-color:#000000;border-bottom-style:solid}.c28{border-right-style:solid;padding:5pt 5pt 5pt 5pt;border-bottom-color:#000000;border-top-width:1pt;border-right-width:1pt;border-left-color:#000000;vertical-align:top;border-right-color:#000000;border-left-width:1pt;border-top-style:solid;border-left-style:solid;border-bottom-width:1pt;width:57pt;border-top-color:#000000;border-bottom-style:solid}.c20{border-right-style:solid;padding:5pt 5pt 5pt 5pt;border-bottom-color:#000000;border-top-width:1pt;border-right-width:1pt;border-left-color:#000000;vertical-align:top;border-right-color:#000000;border-left-width:1pt;border-top-style:solid;border-left-style:solid;border-bottom-width:1pt;width:135.8pt;border-top-color:#000000;border-bottom-style:solid}.c33{border-right-style:solid;padding:5pt 5pt 5pt 5pt;border-bottom-color:#000000;border-top-width:1pt;border-right-width:1pt;border-left-color:#000000;vertical-align:top;border-right-color:#000000;border-left-width:1pt;border-top-style:solid;border-left-style:solid;border-bottom-width:1pt;width:99pt;border-top-color:#000000;border-bottom-style:solid}.c24{border-right-style:solid;padding:5pt 5pt 5pt 5pt;border-bottom-color:#000000;border-top-width:1pt;border-right-width:1pt;border-left-color:#000000;vertical-align:top;border-right-color:#000000;border-left-width:1pt;border-top-style:solid;border-left-style:solid;border-bottom-width:1pt;width:111.8pt;border-top-color:#000000;border-bottom-style:solid}.c15{border-right-style:solid;padding:5pt 5pt 5pt 5pt;border-bottom-color:#000000;border-top-width:1pt;border-right-width:1pt;border-left-color:#000000;vertical-align:top;border-right-color:#000000;border-left-width:1pt;border-top-style:solid;border-left-style:solid;border-bottom-width:1pt;width:54.8pt;border-top-color:#000000;border-bottom-style:solid}.c12{border-right-style:solid;padding:5pt 5pt 5pt 5pt;border-bottom-color:#000000;border-top-width:1pt;border-right-width:1pt;border-left-color:#000000;vertical-align:top;border-right-color:#000000;border-left-width:1pt;border-top-style:solid;border-left-style:solid;border-bottom-width:1pt;width:468pt;border-top-color:#000000;border-bottom-style:solid}.c25{border-right-style:solid;padding:5pt 5pt 5pt 5pt;border-bottom-color:#000000;border-top-width:1pt;border-right-width:1pt;border-left-color:#000000;vertical-align:top;border-right-color:#000000;border-left-width:1pt;border-top-style:solid;border-left-style:solid;border-bottom-width:1pt;width:60.8pt;border-top-color:#000000;border-bottom-style:solid}.c36{border-right-style:solid;padding:5pt 5pt 5pt 5pt;border-bottom-color:#000000;border-top-width:1pt;border-right-width:1pt;border-left-color:#000000;vertical-align:top;border-right-color:#000000;border-left-width:1pt;border-top-style:solid;border-left-style:solid;border-bottom-width:1pt;width:84pt;border-top-color:#000000;border-bottom-style:solid}.c16{border-right-style:solid;padding:5pt 5pt 5pt 5pt;border-bottom-color:#000000;border-top-width:1pt;border-right-width:1pt;border-left-color:#000000;vertical-align:top;border-right-color:#000000;border-left-width:1pt;border-top-style:solid;border-left-style:solid;border-bottom-width:1pt;width:81.8pt;border-top-color:#000000;border-bottom-style:solid}.c29{border-right-style:solid;padding:5pt 5pt 5pt 5pt;border-bottom-color:#000000;border-top-width:1pt;border-right-width:1pt;border-left-color:#000000;vertical-align:top;border-right-color:#000000;border-left-width:1pt;border-top-style:solid;border-left-style:solid;border-bottom-width:1pt;width:50.2pt;border-top-color:#000000;border-bottom-style:solid}.c18{border-right-style:solid;padding:5pt 5pt 5pt 5pt;border-bottom-color:#000000;border-top-width:1pt;border-right-width:1pt;border-left-color:#000000;vertical-align:top;border-right-color:#000000;border-left-width:1pt;border-top-style:solid;border-left-style:solid;border-bottom-width:1pt;width:60.7pt;border-top-color:#000000;border-bottom-style:solid}.c22{border-right-style:solid;padding:5pt 5pt 5pt 5pt;border-bottom-color:#000000;border-top-width:1pt;border-right-width:1pt;border-left-color:#000000;vertical-align:top;border-right-color:#000000;border-left-width:1pt;border-top-style:solid;border-left-style:solid;border-bottom-width:1pt;width:46.5pt;border-top-color:#000000;border-bottom-style:solid}.c41{background-color:#ebebeb;color:#505b62;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:11pt;font-family:"Arial";font-style:normal}.c26{padding-top:16pt;padding-bottom:4pt;line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}.c19{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:16pt;font-family:"Arial";font-style:normal}.c0{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:11pt;font-family:"Arial";font-style:normal}.c47{margin-left:36pt;padding-top:0pt;padding-bottom:0pt;line-height:1.15;orphans:2;widows:2;text-align:center}.c14{padding-top:14pt;padding-bottom:4pt;line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}.c3{color:#666666;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:12pt;font-family:"Arial";font-style:normal}.c13{padding-top:18pt;padding-bottom:6pt;line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}.c35{padding-top:0pt;padding-bottom:16pt;line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}.c30{padding-top:0pt;padding-bottom:3pt;line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}.c46{color:#666666;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:15pt;font-family:"Arial";font-style:normal}.c4{color:#434343;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:14pt;font-family:"Arial";font-style:normal}.c40{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:26pt;font-family:"Arial";font-style:normal}.c2{padding-top:0pt;padding-bottom:0pt;line-height:1.15;orphans:2;widows:2;text-align:left;height:11pt}.c34{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:11pt;font-family:"Arial"}.c7{padding-top:0pt;padding-bottom:0pt;line-height:1.15;orphans:2;widows:2;text-align:left}.c8{border-spacing:0;border-collapse:collapse;margin-right:auto}.c1{padding-top:0pt;padding-bottom:0pt;line-height:1.0;text-align:left}.c5{text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;text-decoration:underline}.c27{background-color:#ffffff;max-width:468pt;padding:72pt 72pt 72pt 72pt}.c11{color:inherit;text-decoration:inherit}.c17{margin-left:36pt;padding-left:0pt}.c43{padding:0;margin:0}.c45{height:48.8pt}.c32{height:7.5pt}.c21{font-style:italic}.c38{background-color:#ffffff}.c42{height:36.8pt}.c39{height:27pt}.c10{height:0pt}.c44{height:25.5pt}.c48{height:27.2pt}.c37{height:23.9pt}.c31{margin-left:108pt}.c23{height:49.5pt}.title{padding-top:0pt;color:#000000;font-size:26pt;padding-bottom:3pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}.subtitle{padding-top:0pt;color:#666666;font-size:15pt;padding-bottom:16pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}li{color:#000000;font-size:11pt;font-family:"Arial"}p{margin:0;color:#000000;font-size:11pt;font-family:"Arial"}h1{padding-top:20pt;color:#000000;font-size:20pt;padding-bottom:6pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h2{padding-top:18pt;color:#000000;font-size:16pt;padding-bottom:6pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h3{padding-top:16pt;color:#434343;font-size:14pt;padding-bottom:4pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h4{padding-top:14pt;color:#666666;font-size:12pt;padding-bottom:4pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h5{padding-top:12pt;color:#666666;font-size:11pt;padding-bottom:4pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h6{padding-top:12pt;color:#666666;font-size:11pt;padding-bottom:4pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;font-style:italic;orphans:2;widows:2;text-align:left}</style></head><body class="c27"><div><p class="c2"><span class="c0"></span></p></div><p class="c30 title" id="h.k6v4307u1w1k"><span class="c40">Social Media Content Filter</span></p><p class="c35 subtitle" id="h.dhy770g9jxnl"><span>By: </span><span class="c5"><a class="c11" href="https://www.google.com/url?q=https://github.com/drkinder&amp;sa=D&amp;source=editors&amp;ust=1639968846963000&amp;usg=AOvVaw0z9C7idVN6Xg00dvzn_1fu">Dylan Kinder</a></span><span>, </span><span class="c5"><a class="c11" href="https://www.google.com/url?q=https://github.com/rmaloney820&amp;sa=D&amp;source=editors&amp;ust=1639968846963000&amp;usg=AOvVaw0zw0BMc_tibppXMb-LDId4">Ryan Maloney</a></span><span>, and </span><span class="c5"><a class="c11" href="https://www.google.com/url?q=https://github.com/mphillipsjr96&amp;sa=D&amp;source=editors&amp;ust=1639968846964000&amp;usg=AOvVaw2yIJPw3P6l-tgkwIUhc2v6">Michael Phillips</a></span></p><h2 class="c13" id="h.n8867cy4zad7"><span class="c19">Introduction</span></h2><p class="c7"><span class="c0">Social media often has a culture of negativity and pessimism, which can have detrimental effects on users&#39; mental health (1) and even drive them away from using social media entirely (2). These platforms clearly have great potential as a communication medium and as a way for users to stay connected and informed with the world around them, but they do not currently provide users with enough tools to curate their feeds with respect to negativity. We aimed to solve this problem by building a sentiment filtering Chrome extension, initially focused on Twitter. Our extension supports several methods of filtering: users can input specific words that they want to avoid which are then expanded upon with a thesaurus, and users can dictate how much negativity they are willing to tolerate with a slider to allow more, or less negativity. The slider setting serves as a threshold for the output of our sentiment classifier, which attained 73% accuracy on our training data and 70% accuracy on a test set of human-labeled tweets. In the future, we are aiming to extract additional features to deploy better models within the constraints we discovered while deploying the current model (chiefly, the relationship between model size and speed) and explore supporting social media platforms beyond Twitter.</span></p><p class="c2"><span class="c0"></span></p><h2 class="c13" id="h.c878fwc4oc4z"><span class="c19">The Chrome Extension</span></h2><p class="c7"><span class="c5"><a class="c11" href="https://www.google.com/url?q=https://drive.google.com/file/d/13yO6mPtxTqj4AYpi_U0MChJdoHegSXhH/view?usp%3Dsharing&amp;sa=D&amp;source=editors&amp;ust=1639968846965000&amp;usg=AOvVaw1c4UNORrU1U5Q7K5KkabTo">Video</a></span></p><h3 class="c26" id="h.q0qc7v42y9lp"><span class="c4">Architecture Overview</span></h3><p class="c7"><span class="c0">The Twitter Content Filter Chrome Extension required a full stack web application with the frontend being the Chrome Extension running HTML, CSS, and JavaScript in the browser with a Python-powered API deployed in Google Cloud. For a high level overview of the architecture and a glimpse at our Tweet classification algorithm, see the following flowchart.</span></p><p class="c2"><span class="c0"></span></p><p class="c7"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 416.39px; height: 535.50px;"><img alt="" src="images/image15.jpg" style="width: 416.39px; height: 535.50px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><h3 class="c26" id="h.dnqc2aupg6qd"><span>Backend</span></h3><h4 class="c14" id="h.kyq0s2f040n9"><span>API Framework</span></h4><p class="c7"><span class="c0">We used the Python library fastapi to build a few API endpoints for the extension. We chose this framework primarily for its simplicity and speed. We did not want our extension to alter the user experience of Twitter and needed a light and fast framework. Additionally, our extension relies on a single endpoint without user authentication, so there is no need for a more complex framework that threatens the speed of our live predictions. We also appreciated the simplicity of fastapi&rsquo;s self-generating API documentation. </span></p><h4 class="c14" id="h.c9qx0lek0cb7"><span>Google Cloud Platform</span></h4><p class="c7"><span>The deployed repository is available on Github </span><span class="c5"><a class="c11" href="https://www.google.com/url?q=https://github.com/drkinder/content-filter-api&amp;sa=D&amp;source=editors&amp;ust=1639968846967000&amp;usg=AOvVaw2bM37Rs36yp5GjrAPnbFg8">here</a></span><span>. </span><span class="c0">The API was deployed on Google Cloud Platform (GCP) through Cloud Build. The extension relies on Cloud Run to handle requests and run our machine learning model. Cloud Run is stateless, significantly reducing the monthly cost as Cloud Run only runs and charges when serving requests. The alternative service to Cloud Run in GCP for this project would be the App Engine, which runs and charges 24/7. Cloud Run is often 90-99% cheaper than using the App Engine. With this said, the App Engine may be better suited for serving live ML predictions as it can hold the model loaded into memory 24/7, increasing the speed of predictions without the burden of having to load the model into memory for every request.</span></p><p class="c2"><span class="c0"></span></p><p class="c7"><span class="c0">Through Cloud Build, we were able to streamline our development process by automatically triggering a cloud rebuild whenever an update is pushed to the main branch of our API&rsquo;s Github repository. This allowed everyone to work asynchronously to build better models and quickly deploy them to the cloud for live testing. </span></p><h4 class="c14" id="h.oah5kfb4okdg"><span class="c3">Serving Predictions - Endpoints</span></h4><p class="c7"><span>Automatically generated API documentation is available </span><span class="c5"><a class="c11" href="https://www.google.com/url?q=https://content-filter-api-js23pan5iq-uc.a.run.app/docs%23/&amp;sa=D&amp;source=editors&amp;ust=1639968846968000&amp;usg=AOvVaw0OtFy0A6e4uZBBaB9-oRg5">here</a></span><span class="c0">. There are multiple endpoints available, each mapping to different classification models. Every endpoint is accessible via HTTP POST method and all endpoints expect the same request body structure. For simplicity, we have placed our best performing model under the /filter-twitter-content/ endpoint. Below is an example cURL request to this endpoint:</span></p><p class="c2"><span class="c0"></span></p><a id="t.9fe34a6f7c0018c9d2389ebf2bb8fd00969305e9"></a><a id="t.0"></a><table class="c8"><tbody><tr class="c10"><td class="c12" colspan="1" rowspan="1"><p class="c1"><span class="c0">curl --location --request POST &#39;https://content-filter-api-js23pan5iq-uc.a.run.app/filter-twitter-content/&#39; \</span></p><p class="c1"><span class="c0">--header &#39;Content-Type: application/json&#39; \</span></p><p class="c1"><span class="c0">--data-raw &#39;{</span></p><p class="c1"><span class="c0">&nbsp; &nbsp; &quot;body&quot;: &quot;This is an example of a Tweet&rsquo;s content&quot;,</span></p><p class="c1"><span class="c0">&nbsp; &nbsp; &quot;threshold&quot;: 0.55,</span></p><p class="c1"><span class="c0">&nbsp; &nbsp; &quot;filter_words&quot;: [</span></p><p class="c1"><span class="c0">&nbsp; &nbsp; &nbsp; &nbsp; &quot;test&quot;,</span></p><p class="c1"><span class="c0">&nbsp; &nbsp; &nbsp; &nbsp; &ldquo;example&rdquo;</span></p><p class="c1"><span class="c0">&nbsp; &nbsp; ]</span></p><p class="c1"><span class="c0">}&#39;</span></p></td></tr></tbody></table><p class="c2"><span class="c0"></span></p><p class="c7"><span class="c0">Note: the JSON body keys &ldquo;filter_words&rdquo; and &ldquo;threshold&rdquo; are optional. If not provided, they will take the default values of [] and 0.55 respectively.</span></p><p class="c2"><span class="c0"></span></p><p class="c7"><span class="c0">The threshold variable can be used to control the classification cutoff of the model. If the predicted probability of a Tweet being positive is less than or equal to the threshold, it will be classified as &ldquo;negative&rdquo; and filtered. The filtered_words variable allows users the option to provide a list of words or topics they would like to filter from their Twitter feed. In this case, in addition to checking for negativity, the Tweet will also be analyzed to determine whether its text explicitly includes or includes related topics to any of the words in the filter_words list. If using this feature, it&rsquo;s possible that even Tweets with a very high probability of being positive will be filtered out if the Tweet is determined to be related to any of the words in the filter_words list.</span></p><p class="c2"><span class="c0"></span></p><p class="c7"><span class="c0">An example response from the API is shown below:</span></p><p class="c2"><span class="c0"></span></p><a id="t.bfedcfbbfe0bfae41e5e0cd2da3e48eee3dbf8a8"></a><a id="t.1"></a><table class="c8"><tbody><tr class="c10"><td class="c12" colspan="1" rowspan="1"><p class="c1"><span class="c0">{</span></p><p class="c1"><span class="c0">&nbsp; &nbsp; &quot;filter&quot;: bool,</span></p><p class="c1"><span class="c0">&nbsp; &nbsp; &quot;confidence_positive&quot;: float or null</span></p><p class="c1"><span class="c0">}</span></p></td></tr></tbody></table><p class="c2"><span class="c0"></span></p><p class="c7"><span class="c0">filter: should the Tweet be filtered?</span></p><p class="c7"><span>confidence_positive: range 0 to 1 of how confident the model is that the Tweet is positive or null if the Tweet never made it to the model because it was not in English or it contained a user-specified filter word.</span></p><h3 class="c26" id="h.btlay9ptggha"><span class="c4">Frontend</span></h3><h4 class="c14" id="h.w87r6zhrbz5v"><span class="c3">Design Goals</span></h4><p class="c7"><span>In an effort to address the ethical implications of altering the content visible in a user&rsquo;s Twitter feed, we tried to provide as much control to the user as possible. First, it was important to us that each user could set their own </span><span class="c21">negativity threshold</span><span class="c0">, which we achieved through the use of a horizontal slider. We also wanted to provide the opportunity for users to choose specific words or topics of content that they would like to filter from their Twitter feeds. We felt that with these two parameters left to the control of each individual user, they would be better equipped to use the Chrome extension in a way that is beneficial to them. An additional goal was to make the interface as easy to use and to understand as possible. Working with an extension creates space restrictions so it was necessary to keep our design compact without suffering loss in usability.</span></p><h4 class="c14" id="h.meuavylghvh7"><span class="c3">The Slider - Negativity Threshold</span></h4><p class="c7"><span class="c0">The slider in the Chrome extension controls the threshold parameter. This threshold parameter acts as the minimum cutoff predicted probability of a Tweet being positive required for the Tweet to appear in a user&rsquo;s feed. In practice, increasing the threshold will hide more and more content while decreasing the threshold will allow more and more to be shown in the user&rsquo;s feed. Because threshold maps directly to predicted probability, it must range between 0 and 1. </span></p><p class="c2"><span class="c0"></span></p><p class="c7"><span class="c0">We considered allowing the user to type in a threshold value but found it much less user friendly than a slider. The first version of the slider used 0 and 1 as labels for the extreme positions but we had concerns that it might be challenging for some users to conceptualize the significance of 0 and 1. Effectively communicating the significance of these numbers was made even more difficult due to the limited space available in a Chrome extension. For these reasons, we decided to change the labels to the more intuitive values &ldquo;less&rdquo; and &ldquo;more&rdquo; and changed the slider label from the vague &ldquo;Negativity Threshold&rdquo; to &ldquo;How much negativity are you willing to tolerate?&rdquo;. Because it makes more intuitive sense that decreasing the slider value aligns with the label &ldquo;less&rdquo; and increasing it aligns with the label &ldquo;more&rdquo;, we also had to inverse the slider so that it ranged from 1 at the left-most position and 0 at the right-most.</span></p><p class="c2"><span class="c0"></span></p><p class="c7"><span class="c0">One of our most important goals for this project was to avoid harming the user experience of Twitter. We aimed to have our Chrome extension running silently in the background. We didn&rsquo;t want the user to have to wait any longer than normal for new Tweets to load, cause the page to crash, or any visible strange behavior such as Tweets disappearing. To support this objective, we decided to limit the threshold value that the user can select between 0.2 and 0.8. Without limiting, setting the threshold to 0 would not filter anything while setting it to 1 would filter everything and essentially break Twitter. Restricting the max threshold to 0.8 helps prevent this; however, it&rsquo;s possible even with a maximum threshold of 0.8, the user may still experience disruptions as the majority of Twitter content does not receive a prediction probability of being 0.8 likely positive or more. For the lower limit of 0.2, we found our model performed exceptionally well at correctly classifying negative Tweets if its probability of the Tweet being positive was below 0.2. Visualizing the accuracy at or below this threshold level provided a clear cutoff value, where anything under 0.2 predicted probability of being positive is very likely indeed negative. We would like to continue optimizing the maximum and minimum threshold values, as well as the best default value in the future.</span></p><h4 class="c14" id="h.fhxal1hbho79"><span class="c3">Word/Topic Filtering</span></h4><p class="c7"><span class="c0">Fortunately, the idea of filtering specific words or topics is much easier to conceptualize than prediction probability cutoff values. The current Chrome extension allows the user to easily type in a word to filter and click a button to add it to the list which appears in the extension as two columns of words. If the word or topic is long, it will dynamically adjust the position to put the word in a single row, even spanning multiple lines if the keyword is long enough. Every keyword has an &ldquo;x&rdquo; to the left of it, allowing the user to individually remove words previously added.</span></p><h4 class="c14" id="h.cwt5g06y0hqg"><span class="c3">Reset to Default Settings</span></h4><p class="c7"><span class="c0">Through our personal experience testing and working with the extension, we realized clearing many words added to the filter list at once was cumbersome. Each word required its own click to clear. In an effort to speed up clearing the filtered word list, we added a button to the button labeled &ldquo;Reset to Default Settings&rdquo;. This button will also reset the negativity threshold slider to the default 0.5 middle position.</span></p><h3 class="c26" id="h.ogb31v4qkxyj"><span class="c4">Twitter</span></h3><h4 class="c14" id="h.7pxthec75xq0"><span class="c3">Supported Pages</span></h4><p class="c7"><span>The extension in its current state works on /home, /explore, and user profiles. Because Twitter is a single-page application, it was challenging to determine which page the user is on. If the page refreshed when switching between pages, it would have been easier to listen for this and update the page accordingly. Instead we opted to determine the page based on the aria-label property of the HTML div element of the Timeline (the center console where Tweets are rendered). We appreciated this human-readable page label. Examples of this property for the Home page and the Explore page are &ldquo;Timeline: Your Home Timeline&rdquo; and &ldquo;Timeline: Explore&rdquo;. These proved to be a reliable method for quickly determining which page the user was on. The page the user is on requires slightly different logic to properly capture, render, and hide Tweets.</span></p><h4 class="c14" id="h.ojocrjg0ugwt"><span>Classifying Tweets</span></h4><p class="c7"><span class="c0">Because our model must be loaded into memory on the backend for each API request, we had hoped to bundle multiple Tweets in every request to reduce the workload of our server and therefore, increase prediction speed. Unfortunately, the way that Twitter loads new Tweets complicates this objective. Twitter begins by loading three Tweets, allowing us to bundle these initial Tweets into a single request; however, all following Tweets are loaded individually as the user scrolls down their Timeline. To avoid disruption in the user experience of Twitter, we were forced to also classify each Tweet individually. Fortunately, our server appears to be handling this well supporting at least a few users concurrently. The exact number of concurrent users that our API can support remains unclear.</span></p><h4 class="c14" id="h.tyi6tsi7xqr0"><span class="c3">Hiding Negative Tweets</span></h4><p class="c7"><span>We initially tried to capture the entire HTML content of the Tweet and hold it from being inserted into Twitter&rsquo;s Timeline. This approach was very difficult to manage and introduced disruptions in the user experience. Our second approach was to allow the HTML for a new Tweet to be loaded into the Timeline; however, we would apply some CSS to it so that it would be completely invisible for the user. After sending the content of the Tweet to our model, we could use the prediction to determine whether to remove our CSS, allowing the user to see it. Under normal scrolling conditions, new Tweets are loaded in before the scrolling user arrives at them providing time for our extension, API, and model to run before the user arrives at the Tweet so there are usually not strange situations where Tweets just &ldquo;appear&rdquo; on the screen after the pipeline returns a decision. With this said, scrolling extremely quickly, too fast to read any of the Tweets can produce instances of this strange behavior. </span></p><h3 class="c26" id="h.jc6tkqnr16i5"><span class="c4">Download and Installation Instructions</span></h3><ol class="c43 lst-kix_bj4jmq89m33u-0 start" start="1"><li class="c7 c17 li-bullet-0"><span>Download the Chrome Extension from Github </span><span class="c5"><a class="c11" href="https://www.google.com/url?q=https://github.com/drkinder/content-filter-chrome-extension&amp;sa=D&amp;source=editors&amp;ust=1639968846976000&amp;usg=AOvVaw1zi8mB9ysFfq3ENTZ14btl">here</a></span><span class="c0">.</span></li><li class="c7 c17 li-bullet-0"><span class="c0">Open your Google Chrome Browser and click on the puzzle icon at the top right corner of the browser, just below the minimize, resize, and exit buttons. </span></li><li class="c7 c17 li-bullet-0"><span class="c0">Click on &quot;Manage Extensions&quot;. </span></li><li class="c7 c17 li-bullet-0"><span class="c0">Check the top right corner to make sure &ldquo;Developer Mode&rdquo; is toggled on. </span></li><li class="c7 c17 li-bullet-0"><span class="c0">Now in the top left corner of the page, click &ldquo;Load unpacked&rdquo;. </span></li><li class="c7 c17 li-bullet-0"><span class="c0">Find the extension directory on your computer downloaded from GitHub and select it. You should see a card with the label &ldquo;Content Filter&rdquo; appear in your list of installed Extensions. Note: if you see an error about a missing manifest.json file, make sure you select the directory containing the manifest.json file.</span></li><li class="c7 c17 li-bullet-0"><span class="c0">Pin this extension to your browser to make interacting with it easier by clicking the puzzle piece icon again, find &quot;Twitter Content Filter&quot; and click the pin icon. </span></li><li class="c7 c17 li-bullet-0"><span class="c0">Go to Twitter or refresh Twitter if you were already on the page before loading the extension. The extension will begin working in the background with default settings. To add your own customer words to filter and tune the filter threshold to your preferred settings, click on the pinned extension with the letter &quot;T&quot;.</span></li></ol><p class="c2"><span class="c0"></span></p><p class="c2"><span class="c0"></span></p><h2 class="c13" id="h.4dx90asel2g6"><span class="c19">What is negativity?</span></h2><p class="c7"><span class="c0">With the decision to filter negative posts out of a feed, we had to come to a consensus on what we mean by &ldquo;negative&rdquo;. Negative sentiment is a somewhat subjective, nebulous concept that likely exists on a spectrum rather than being binary. In fact, when asked to label tweets, human annotators exhibit varying degrees of agreement on sentiment; depending on the dataset, it has ranged from about 60% to 80% with even lower agreement on phrase subsets of tweets (~40%) (3). Achieving objectively high sentiment classification accuracy on tweets is therefore difficult given the variability in individual perception of negativity. This is why we aimed to give the user control over the extent of negativity they see both through the word/topic filtering and slider control. Ideally, as users become accustomed to the consequences of word/topic filtering selection and slider setting, they can decide on a setting that fits their individual perception of negativity.</span></p><h2 class="c13" id="h.3bn57kk548gg"><span class="c19">Dataset</span></h2><p class="c7"><span>For model experimentation and training, we used the Sentiment140 dataset, available on </span><span class="c5"><a class="c11" href="https://www.google.com/url?q=https://www.kaggle.com/kazanova/sentiment140&amp;sa=D&amp;source=editors&amp;ust=1639968846978000&amp;usg=AOvVaw2h_AzuWFTcBnD1J80ou3IY">kaggle</a></span><span class="c0">&nbsp;and the original author&rsquo;s website and publication (4,5). A very commonly used dataset for initial exploration and training of sentiment analysis models, this dataset used emoticons to classify negativity vs. positivity, and contains 1.6 million tweets evenly split between positive and negative sentiment with the emoticons stripped out. The possible shortcomings of this dataset center around its handling of emojis - positive emojis may be more likely to convey positive sentiment, but they do not always. Additionally, we would have preferred the emojis remain in the training data as emoji use has only become more prevalent since this dataset was built and emojis can be a useful tool for conveying sentiment. Despite these shortcomings, models built on this dataset did perform reasonably well on our small test set of human-labeled tweets from October 2021, which is described in detail below.</span></p><h2 class="c13" id="h.6nhefuoupkn5"><span class="c19">Preprocessing</span></h2><p class="c7"><span>Preprocessing took two paths, depending on which final feature representation and model was planned. Below, we discuss the preprocessing methods for creating a TF-IDF representation pipeline (LSI) and word vector (GloVE and FastText) representations of tweets.</span></p><h3 class="c26" id="h.u99j4yj31fxb"><span>Latent Semantic Indexing</span></h3><p class="c7"><span class="c0">We took a handful of steps to preprocess our training data and, in turn, the live tweets as they pass through our model. The first step we took was to tokenize and lemmatize the tweets by passing them through the preprocess_string() function from gensim. Once they were processed, we removed stop words from the tokens. To create a better set of training data, we also created bigrams using the Phrases() function from gensim. We created those bigrams when two words appeared next to each other at least 20 times.</span></p><p class="c2"><span class="c0"></span></p><a id="t.f17de58a04dda88def595e8f13be93e03ff2ac6a"></a><a id="t.2"></a><table class="c8"><tbody><tr class="c32"><td class="c12" colspan="1" rowspan="1"><p class="c7"><span class="c0">phrase_model = Phrases(tweet_df[&#39;tokens&#39;],min_count=20,threshold=2).freeze()</span></p></td></tr></tbody></table><h3 class="c26" id="h.t6hm3rpb6coh"><span class="c4">Word/Character Embeddings: GloVE and FastText</span></h3><p class="c7"><span class="c0">Preprocessing for converting the tweets into an averaged word vector was performed with the goal of making the tokens match the formatting of the GloVE (6) and FastText (7,8) word dictionaries as closely as possible. In this case, unlike preprocessing for LSI, we wanted to avoid lemmatization; full words were present in GloVE, and in FastText, character-level representations are used so lemmatization could be detrimental. The Tweet Preprocessor library was used to do basic cleaning of the tweets prior to tokenization. This library allows users to select which typical tweet features they would like stripped - in our case, we filtered URLs, mentions, and numbers prior to tokenization. The library provides support for stripping out hashtags and their attached words/phrases, but we elected to keep hashtags, then strip away the actual hashtag in a subsequent step given the possibility that words in hashtags (not the hashtags themselves) could convey sentiment. TweetTokenizer from the NLTK library was used next, which had several useful options for manipulating tokens to be more likely to match those in the word embeddings, such as lowercasing all tokens and reducing the length of certain tokens (for example, &lsquo;lmaooooooo&rsquo; shortened to &lsquo;lmaooo&rsquo;).</span></p><p class="c2"><span class="c0"></span></p><p class="c7"><span>With the tokenized tweets, an average word vector generator function was applied that looked up each token in the word embedding collections and computed the average of the collected word vectors. The GloVE embeddings we used were trained on a large corpus of tweets and came in a range of feature sizes (25, 50, 100, 200 features). We used FastText&rsquo;s standard English language model that was trained on Wikipedia and Common Crawl that has a default of 300 features, but we also reduced the feature size to 200, 100, and 50 as well to examine smaller feature sets similar to that of the GloVE embeddings. The functions to extract word vectors differed slightly; since FastText uses character-level word embeddings, there is no need to establish a vocabulary to lookup a word vector, it is instead computed based on the characters sequence passed into the get_word_vector function. One benefit we envisioned from using GloVE/FastText embeddings was that the total feature numbers are much smaller than the result of vectorizing a large corpus with CountVectorizer/TfidfVectorizer; the scale of features opened up the possibility of trying out models more appropriate for smaller feature sets, like Random Forests and XGBoost. These efforts are described below in the Models section.</span></p><h2 class="c13" id="h.62pqvtqxcv2p"><span class="c19">Models</span></h2><p class="c7"><span>In order to get the best results we could, we experimented with numerous different models with different parameters. In the case of Latent Semantic Indexing, we explored Multinomial Naive Bayes, a Stochastic Gradient Descent Classifier, and a Linear Support Vector Classifier. For the two types of word embeddings, we tested Linear Regression, Random Forest, and XGBoost.</span></p><h3 class="c26" id="h.swak27qoyhve"><span class="c4">Latent Semantic Indexing</span></h3><p class="c7"><span class="c0">For LSI, we utilized pipelines for our model testing. Each pipeline started off with a CountVectorizer, then a TFIDFTransformer, and finally the specific model.</span></p><p class="c2"><span class="c0"></span></p><a id="t.03b908fdccccdf733c28b07f134ff7f9923f668f"></a><a id="t.3"></a><table class="c8"><tbody><tr class="c23"><td class="c12" colspan="1" rowspan="1"><p class="c1"><span class="c0">Pipeline([(&#39;vect&#39;, CountVectorizer(stop_words=&#39;english&#39;,ngram_range=(1,3))),</span></p><p class="c1"><span class="c0">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;(&#39;tfidf&#39;, TfidfTransformer(use_idf=False)),</span></p><p class="c1"><span class="c0">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; (&#39;clf&#39;, &nbsp;model)])</span></p></td></tr></tbody></table><p class="c2"><span class="c0"></span></p><p class="c7"><span>While hyper-tuning the parameters, we utilized GridSearch. This was used to identify the &ldquo;best&rdquo; parameters for our models, given a list of parameters to try. GridSearch execution was quite lengthy as it tested each combination of parameters that we gave it. Sometimes the run time was over 24 hours.</span></p><p class="c2 c31"><span class="c0"></span></p><p class="c7"><span>The models we used for LSI were Multinomial Naive Bayes, </span><span class="c0">Stochastic Gradient Descent Classifier, and Linear Support Vector Classifier. We chose these models because we need to classify whether a Tweet is negative or positive(neutral). These also gave us the ability to see how negative a Tweet was instead of just classifying it as negative or positive. This allowed the use of the slider function as mentioned above.</span></p><h4 class="c14" id="h.r2mhosr87smx"><span class="c3">Multinomial Naive Bayes</span></h4><a id="t.839931d06d2f3a145e4b7ce9d6a493d27f3919be"></a><a id="t.4"></a><table class="c8"><tbody><tr class="c39"><td class="c20" colspan="1" rowspan="1"><p class="c1"><span class="c0">model = MultinomialNB()</span></p></td></tr></tbody></table><p class="c2"><span class="c0"></span></p><h4 class="c14" id="h.9qeqr9242n2x"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 379.00px; height: 123.00px;"><img alt="" src="images/image2.png" style="width: 379.00px; height: 123.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 224.35px; height: 200.35px;"><img alt="" src="images/image5.png" style="width: 224.35px; height: 200.35px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></h4><p class="c7"><span class="c21 c34">0 is negative, 4 is positive</span></p><p class="c7"><span>MNB had the best recall for negative tweets. It&rsquo;s performance was similar to LinearSVC. It had similar size to LinearSVC, but about 1% less accuracy on average.</span></p><h4 class="c14" id="h.y66wif8h488n"><span class="c3">Stochastic Gradient Descent Classifier</span></h4><a id="t.4a0590c476aae4dc1c5bce562b1594956e54e563"></a><a id="t.5"></a><table class="c8"><tbody><tr class="c48"><td class="c12" colspan="1" rowspan="1"><p class="c7"><span class="c0">model = SGDClassifier(loss=&rsquo;log&rsquo;, penalty=&#39;l2&#39;, alpha=1e-3, random_state=RANDOM_SEED))</span></p></td></tr></tbody></table><h4 class="c14" id="h.wpirsbiqpcx1"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 377.00px; height: 126.00px;"><img alt="" src="images/image7.png" style="width: 377.00px; height: 126.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 224.64px; height: 200.22px;"><img alt="" src="images/image11.png" style="width: 224.64px; height: 200.22px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></h4><p class="c7"><span class="c34 c21">0 is negative, 4 is positive</span></p><p class="c7"><span class="c0">SGD Classifier gave us the best recall for positive tweets, but the worst for negative tweets. The precision and f1-scores were on par with the rest. The size of these models were the smallest, but had the worst accuracy ceiling compared to the other models.</span></p><p class="c2"><span class="c0"></span></p><p class="c2"><span class="c0"></span></p><h4 class="c14" id="h.2h17rbe49mqu"><span class="c3">Linear Support Vector Classifier</span></h4><a id="t.7c431c50727ef89488c086ebe8ebd511a21fcf84"></a><a id="t.6"></a><table class="c8"><tbody><tr class="c45"><td class="c12" colspan="1" rowspan="1"><p class="c1"><span class="c0">model = CalibratedClassifierCV(base_estimator=LinearSVC(tol=1e-4,penalty=&#39;l2&#39;,dual=False,random_state=RANDOM_SEED),cv=5))</span></p></td></tr></tbody></table><p class="c2"><span class="c0"></span></p><p class="c7"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 378.00px; height: 124.00px;"><img alt="" src="images/image16.png" style="width: 378.00px; height: 124.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 224.64px; height: 200.22px;"><img alt="" src="images/image8.png" style="width: 224.64px; height: 200.22px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c7"><span class="c34 c21">0 is negative, 4 is positive</span></p><p class="c7"><span class="c0">We added CalibratedClassifierCV to this model, so that we would be able to get prediction probabilities into our model. LinearSVC was the best performing model we had. With more training data, the performance kept improving. Size was the limiting factor for this.</span></p><h3 class="c26" id="h.qc39l0ha8h0a"><span class="c4">GloVE and FastText</span></h3><p class="c7"><span class="c0">To explore the potential of GloVE and FastText features, we performed GridSearchCV on 10,000 tweet samples to get a sense of which hyperparameters provided the best performance for the models under evaluation.</span></p><h4 class="c14" id="h.flv0f95nqbw4"><span class="c3">Logistic Regression</span></h4><a id="t.33d6fc105d7437da9c10f2bd9e9bcdb6c750f37c"></a><a id="t.7"></a><table class="c8"><tbody><tr class="c42"><td class="c12" colspan="1" rowspan="1"><p class="c1"><span class="c0">GloVE: model = LogisticRegression(C=1, penalty=&rsquo;l1&rsquo;), fitted with 200 features</span></p><p class="c1"><span class="c0">FastText: model = LogisticRegression(C=10, penalty=&rsquo;l2&rsquo;), fitted with 300 features</span></p></td></tr></tbody></table><p class="c2"><span class="c0"></span></p><p class="c7"><span class="c0">The first model we explored for word embeddings was Logistic Regression. Normally, using StandardScaler on features prior to fitting Logistic Regression is recommended; in this case, StandardScaler made very little difference on the output of our GridSearch that we used to decide upon the extent of regularization (C value) and the method of regularization (L1 vs. L2). This is not surprising given that the values of word vectors for both the GloVE and FastText embeddings are frequently, but not always, bounded between -1 and 1. The mean-centering performed by the StandardScaler is thus not likely to have a major impact on the values of the features. The best results from a GridSearch performed with 10,000 training tweets for each feature representation are below.</span></p><p class="c2"><span class="c0"></span></p><a id="t.654cdd32a71c1d43600a52a31903670aa8fca6e0"></a><a id="t.8"></a><table class="c8"><tbody><tr class="c37"><td class="c18" colspan="1" rowspan="1"><p class="c1"><span class="c0">Features</span></p></td><td class="c36" colspan="1" rowspan="1"><p class="c1"><span class="c0">Feature Count</span></p></td><td class="c33" colspan="1" rowspan="1"><p class="c1"><span class="c0">Parameters</span></p></td><td class="c25" colspan="1" rowspan="1"><p class="c1"><span class="c0">Accuracy</span></p></td><td class="c28" colspan="1" rowspan="1"><p class="c1"><span class="c0">Precision</span></p></td><td class="c22" colspan="1" rowspan="1"><p class="c1"><span class="c0">Recall</span></p></td><td class="c25" colspan="1" rowspan="1"><p class="c1"><span class="c0">F1 Score</span></p></td></tr><tr class="c10"><td class="c18" colspan="1" rowspan="1"><p class="c1"><span class="c0">GloVE</span></p></td><td class="c36" colspan="1" rowspan="1"><p class="c1"><span class="c0">200</span></p></td><td class="c33" colspan="1" rowspan="1"><p class="c1"><span class="c0">C:1, penalty: L1</span></p></td><td class="c25" colspan="1" rowspan="1"><p class="c1"><span class="c0">75.2%</span></p></td><td class="c28" colspan="1" rowspan="1"><p class="c1"><span class="c0">75.3%</span></p></td><td class="c22" colspan="1" rowspan="1"><p class="c1"><span class="c0">74.2%</span></p></td><td class="c25" colspan="1" rowspan="1"><p class="c1"><span class="c0">74.7%</span></p></td></tr><tr class="c10"><td class="c18" colspan="1" rowspan="1"><p class="c1"><span class="c0">FastText</span></p></td><td class="c36" colspan="1" rowspan="1"><p class="c1"><span class="c0">300</span></p></td><td class="c33" colspan="1" rowspan="1"><p class="c1"><span class="c0">C:10, penalty: L2</span></p></td><td class="c25" colspan="1" rowspan="1"><p class="c1"><span class="c0">74.4%</span></p></td><td class="c28" colspan="1" rowspan="1"><p class="c1"><span class="c0">74.4%</span></p></td><td class="c22" colspan="1" rowspan="1"><p class="c1"><span class="c0">73.5%</span></p></td><td class="c25" colspan="1" rowspan="1"><p class="c1"><span class="c0">74.4%</span></p></td></tr></tbody></table><p class="c2"><span class="c0"></span></p><p class="c7"><span class="c0">For both GloVE and FastText, maximizing the number of features for fitting improved accuracy, precision, recall, and the F1 score, while they varied in the best possible regularization parameters. </span></p><h4 class="c14" id="h.9b08rn2nbfi4"><span class="c3">Random Forest</span></h4><a id="t.0ecd4e4d25a1686782639c7582bbc1ca3f5f9513"></a><a id="t.9"></a><table class="c8"><tbody><tr class="c42"><td class="c12" colspan="1" rowspan="1"><p class="c1"><span class="c0">GloVE and FastText: model = RandomForest(n_estimators = 1000, max_features = &lsquo;auto&rsquo;, random_state = 42)</span></p></td></tr></tbody></table><p class="c2"><span class="c0"></span></p><p class="c7"><span class="c0">Both random forest and XGBoost (a gradient-boosted decision tree) benefit from requiring little if any manipulation of features prior to fitting, so we did not perform any feature scaling prior to performing the GridSearch for both of these models. For the random forest, we focused on two hyperparameters: the number of estimators (in our case, 500 vs. 1000), or the number of random trees that are created, and maximum features, which dictates the number of features used to build each tree. The number of features selected to build each tree can influence under/overfitting during tree construction, so we tested auto (or the square root of the total feature number), log2 of the total features, and None, which corresponds to all features being available. Similarly to Logistic Regression, the maximum number of features being available for fitting was beneficial, along with more estimators (1000x) and the auto setting for maximum features selected to examine at each node.</span></p><p class="c2"><span class="c0"></span></p><a id="t.7a3a4192cab1c45077ab3a5eea98710782164029"></a><a id="t.10"></a><table class="c8"><tbody><tr class="c37"><td class="c15" colspan="1" rowspan="1"><p class="c1"><span class="c0">Features</span></p></td><td class="c16" colspan="1" rowspan="1"><p class="c1"><span class="c0">Feature Count</span></p></td><td class="c24" colspan="1" rowspan="1"><p class="c1"><span class="c0">Parameters</span></p></td><td class="c6" colspan="1" rowspan="1"><p class="c1"><span class="c0">Accuracy</span></p></td><td class="c9" colspan="1" rowspan="1"><p class="c1"><span class="c0">Precision</span></p></td><td class="c29" colspan="1" rowspan="1"><p class="c1"><span class="c0">Recall</span></p></td><td class="c6" colspan="1" rowspan="1"><p class="c1"><span class="c0">F1 Score</span></p></td></tr><tr class="c10"><td class="c15" colspan="1" rowspan="1"><p class="c1"><span class="c0">GloVE</span></p></td><td class="c16" colspan="1" rowspan="1"><p class="c1"><span class="c0">200</span></p></td><td class="c24" colspan="1" rowspan="1"><p class="c1"><span class="c0">n_estimators: 1000, max_features: &rsquo;auto&rsquo;</span></p></td><td class="c6" colspan="1" rowspan="1"><p class="c1"><span class="c0">72.7%</span></p></td><td class="c9" colspan="1" rowspan="1"><p class="c1"><span class="c0">72.4%</span></p></td><td class="c29" colspan="1" rowspan="1"><p class="c1"><span class="c0">72.5%</span></p></td><td class="c6" colspan="1" rowspan="1"><p class="c1"><span class="c0">72.5%</span></p></td></tr><tr class="c10"><td class="c15" colspan="1" rowspan="1"><p class="c1"><span class="c0">FastText</span></p></td><td class="c16" colspan="1" rowspan="1"><p class="c1"><span class="c0">300</span></p></td><td class="c24" colspan="1" rowspan="1"><p class="c1"><span class="c0">n_estimators: 1000, max_features: &lsquo;auto&rsquo;</span></p></td><td class="c6" colspan="1" rowspan="1"><p class="c1"><span class="c0">69.5%</span></p></td><td class="c9" colspan="1" rowspan="1"><p class="c1"><span class="c0">69.1%</span></p></td><td class="c29" colspan="1" rowspan="1"><p class="c1"><span class="c0">69.3%</span></p></td><td class="c6" colspan="1" rowspan="1"><p class="c1"><span class="c0">69.2%</span></p></td></tr></tbody></table><p class="c2"><span class="c0"></span></p><h4 class="c14" id="h.9aj44ueg497e"><span class="c3">XGBoost Classifier</span></h4><a id="t.117a6a37284c2906b2561b4e6ae89b86f1b8eafc"></a><a id="t.11"></a><table class="c8"><tbody><tr class="c44"><td class="c12" colspan="1" rowspan="1"><p class="c1"><span class="c0">GloVE and FastText: model = XGBClassifier(n_estimators = 250, max_depth = 50, eta=0.5)</span></p></td></tr></tbody></table><p class="c2"><span class="c0"></span></p><p class="c7"><span class="c0">XGBoost (9), a gradient-boosted tree classifier, is the final method we fit the GloVE and FastText embeddings with. XGBoost has a number of hyperparameters available for tuning that can be influential; we focused on tuning the number of estimators (n_estimators), the maximum tree depth (max_depth), and the learning rate (eta). XGBoost&rsquo;s default tree depth is 6, and boosting this parameter can lead to overfitting. Given the large amount of data and many features available, we found that higher values improved fitting (n=50). As previously, better results were achieved with more features and more estimators. A higher maximum depth and learning rate also contributed to superior performance. Further boosting the n_estimators parameter may have improved performance further, but training time was quite significant for XGBoost so the best parameter set from the GridSearch was selected for further development.</span></p><p class="c2"><span class="c0"></span></p><a id="t.1c6f283f22ac46819dde3ede542fe94b21eb5368"></a><a id="t.12"></a><table class="c8"><tbody><tr class="c37"><td class="c15" colspan="1" rowspan="1"><p class="c1"><span class="c0">Features</span></p></td><td class="c16" colspan="1" rowspan="1"><p class="c1"><span class="c0">Feature Count</span></p></td><td class="c24" colspan="1" rowspan="1"><p class="c1"><span class="c0">Parameters</span></p></td><td class="c6" colspan="1" rowspan="1"><p class="c1"><span class="c0">Accuracy</span></p></td><td class="c9" colspan="1" rowspan="1"><p class="c1"><span class="c0">Precision</span></p></td><td class="c29" colspan="1" rowspan="1"><p class="c1"><span class="c0">Recall</span></p></td><td class="c6" colspan="1" rowspan="1"><p class="c1"><span class="c0">F1 Score</span></p></td></tr><tr class="c10"><td class="c15" colspan="1" rowspan="1"><p class="c1"><span class="c0">GloVE</span></p></td><td class="c16" colspan="1" rowspan="1"><p class="c1"><span class="c0">200</span></p></td><td class="c24" colspan="1" rowspan="1"><p class="c1"><span class="c0">n_estimators: 250, max_depth: 50,</span></p><p class="c1"><span class="c0">eta: 0.5</span></p></td><td class="c6" colspan="1" rowspan="1"><p class="c1"><span class="c0">73.5%</span></p></td><td class="c9" colspan="1" rowspan="1"><p class="c1"><span class="c0">73.3%</span></p></td><td class="c29" colspan="1" rowspan="1"><p class="c1"><span class="c0">73.0%</span></p></td><td class="c6" colspan="1" rowspan="1"><p class="c1"><span class="c0">73.1%</span></p></td></tr><tr class="c10"><td class="c15" colspan="1" rowspan="1"><p class="c1"><span class="c0">FastText</span></p></td><td class="c16" colspan="1" rowspan="1"><p class="c1"><span class="c0">300</span></p></td><td class="c24" colspan="1" rowspan="1"><p class="c1"><span class="c0">n_estimators: 250,</span></p><p class="c1"><span class="c0">max_depth: 50</span></p><p class="c1"><span class="c0">eta: 0.5</span></p></td><td class="c6" colspan="1" rowspan="1"><p class="c1"><span class="c0">70.2%</span></p></td><td class="c9" colspan="1" rowspan="1"><p class="c1"><span class="c0">70.0%</span></p></td><td class="c29" colspan="1" rowspan="1"><p class="c1"><span class="c0">70.0%</span></p></td><td class="c6" colspan="1" rowspan="1"><p class="c1"><span class="c0">70.0%</span></p></td></tr></tbody></table><p class="c2"><span class="c0"></span></p><p class="c7"><span class="c0">From the above model experimentation and hyperparameter tuning, we concluded that GloVE embeddings were superior for this application and examined further potential optimizations with those embeddings. We think this is likely because these particular word vectors were actually trained on tweets, unlike the FastText model chosen. It is likely the specific cultural ways in which language is used on Twitter, such as the general informality of it, contributes to this stronger performance. </span></p><p class="c2"><span class="c0"></span></p><p class="c7"><span class="c0">Considering this, we expanded the training data available to the two best models tested with GloVE, Logistic Regression and XGBoost and examined performance. Below are the classification reports for Logistic Regression and XGBoost when trained using the 200 feature GloVE vectors and trained on all training instances (1.2 million tweets, with 400k test tweets) for Logistic Regression, and 500k tweets for XGBoost. XGBoost performs similarly with Logistic Regression when reaching 500k training tweets, and it is possible that further training data (and computation time for fitting) could improve this model further.</span></p><p class="c7"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 332.30px; height: 169.88px;"><img alt="" src="images/image3.png" style="width: 332.30px; height: 169.88px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 331.00px; height: 171.27px;"><img alt="" src="images/image4.png" style="width: 331.00px; height: 171.27px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><h4 class="c14" id="h.pgbtltbszibe"><span class="c3">Results</span></h4><p class="c47"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 501.00px; height: 347.00px;"><img alt="" src="images/image1.png" style="width: 501.00px; height: 347.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c7"><span class="c0">A large part of this project was finding the balance between accuracy and pickle size. The size of the pickled model is important because we are hosting the model on Google Cloud and for each tweet, we&rsquo;re loading and running the model. If we have a large model, such as the SVC model with 79% accuracy and 600mb file size, then it will take several seconds to load the model, for each tweet, which would ruin the user experience of scrolling through Twitter. We came to the conclusion that around 10mb (10,000kb) would be the largest model that wouldn&rsquo;t interfere with the user experience. By using this graphic and that criteria, we decided to apply the SVC model that was around 9mb with an accuracy of 73% for the sentiment filtering.</span></p><p class="c2"><span class="c0"></span></p><p class="c7"><span class="c0">One motivating factor for exploring word vector representations of the tweets was that the scale of features is greatly reduced, and the pickled model size was smaller. However, the benefit of a reduce model size was far outweighed by the necessity to look up each word in the FastText or GloVE dictionaries; the pickled size of the 200 feature GloVE dictionary was over a gigabyte. Nevertheless, we explored building models with these feature representations in case future iterations of the extension are able to work around these issues. With a model deployed, we examined the behavior of the model with a recent batch of tweets labeled by human annotators to further understand its performance.</span></p><h4 class="c14" id="h.lf1anxwzzgd5"><span class="c3">LinearSVC Model Performance on Human-Labeled Tweets</span></h4><p class="c7"><span class="c0">Though we viewed the Sentiment140 Dataset used for training as a sufficient option for model experimentation and training, we had some concerns that it was not a representative dataset for the current state of Twitter that our Chrome extension would be handling. Sentiment140 is fairly old (2009) and relied upon emoticons for classifying tweets as negative or positive, and the dataset itself strips out the emoticons that motivated labeling. Thus, within the dataset, there are likely instances where sentiment is misinterpreted by relying upon emoticons as the sole source of sentiment.</span></p><p class="c2"><span class="c0"></span></p><p class="c7"><span>We therefore aimed to build another test set using a more recent batch of tweets that were human-labeled to assess whether our model performed similarly. The University of Michigan School of Information kindly provided us with </span><span class="c5"><a class="c11" href="https://www.google.com/url?q=https://drive.google.com/drive/u/2/folders/1UY1styN9giBm_GITZikY8P4boW_cxEiz&amp;sa=D&amp;source=editors&amp;ust=1639968847017000&amp;usg=AOvVaw1y6nqyL2a-SVOAYOiaaFd4">several batches of randomized tweets</a></span><span class="c0">&nbsp;collected from the Twitter API in October 2021. The tweets were processed to only English language tweets using the langdetect library, then given a preliminary sentiment label with the VADER algorithm (9) in order to feed a similar amount of negative and positive/neutral tweets to our human labelers. 50 negative tweets (as determined by a VADER sentiment score of &gt;.7 negative) and 25 each of positive or neutral tweets (using the same VADER sentiment threshold as the negative tweets) were randomly selected from the English language tweets and uploaded to a Google Form for labeling.</span></p><p class="c2"><span class="c0"></span></p><p class="c7"><span class="c0">After human labeling (n=14 labelers), the results of the survey were exported to a Google Sheet, then to a pandas dataframe for analysis; tweets were labeled negative or positive based on whether the majority of labelers picked each option. Examining the survey data revealed that there was significant disagreement between VADER and human labelers, with VADER being just 57% accurate when considering the human labelers as the ground truth. Perhaps </span><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 333.50px; height: 158.24px;"><img alt="" src="images/image13.png" style="width: 333.50px; height: 158.24px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 308.45px; height: 237.50px;"><img alt="" src="images/image9.png" style="width: 308.45px; height: 237.50px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c7"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 226.67px;"><img alt="" src="images/image12.png" style="width: 624.00px; height: 226.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c7"><span class="c0">unsurprisingly, there was also notable disagreement between the human labelers on what constitutes a negative or positive tweet, with just 8 of 100 tweets being labeled negative by all humans and 18 of 100 tweets being labeled as positive or neutral by all humans. With the variation in human labeling in mind, we analyzed the performance of the LinearSVC model (9 MB) used in production on the human-labeled tweets. The performance summary, confusion matrix, and ROC-AUC curves below show that the LinearSVC performs similarly on the human-labeled tweets to how it does on the Sentiment140 training and test data, with a small drop in accuracy (69.7% vs. 73.0%). Precision and recall are slightly lower in the Negative sentiment tweets, which could be a reflection of a change in how negativity is expressed currently compared to the training data, but it is also possible that with further human-labeled data we would see more similar performance, given that this is just a small test set. An ROC generated with 100k of the training tweets has a similar shape and AUC to the plot generated with the human-labeled tweets, indicating similar performance between the two datasets.</span></p><p class="c7"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 374.10px; height: 345.70px;"><img alt="" src="images/image10.png" style="width: 374.10px; height: 345.70px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c7"><span class="c0">Given the apparent disagreement between the human labelers on what constitutes a negative or positive tweet, we hypothesized that the total fraction of labelers who tagged a tweet positive/negative could be considered a probability of positivity/negativity in a similar way that the LinearSVC can output predicted probabilities for each class. Since the output of the predict_proba for the positive/neutral class is used in our slider, we examined the differences in our model&rsquo;s predicted probability and the probability designated by humans for both negative and positive/neutral tweets, then examined the distribution of predicted probabilities for both the training data and human-labeled test data.</span><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 378.50px; height: 349.55px;"><img alt="" src="images/image14.png" style="width: 378.50px; height: 349.55px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c2"><span class="c0"></span></p><p class="c7"><span>On both classes of human-labeled tweets, the human labelers generally assigned a higher probability to the assigned class than the LinearSVC classifier did. The LinearSVC could be considered more conservative or less confident in its estimate of sentiment compared to human labelers. While the representation of tweets in a tf-idf matrix provides good prediction accuracy for this task, it is likely missing some features that allow human labelers to be more generally certain of the final label, such as contextual information about the way words are being used - bigrams provide some very local context and two word phrases can certainly associate with negativity or positivity, but their context can still impact their contribution to sentiment. Unlike the training tweets, these test tweets contained emojis, which could be useful for assigning sentiment to human labelers.</span><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 436.00px;"><img alt="" src="images/image6.png" style="width: 624.00px; height: 436.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c7"><span class="c0">We next examined the distribution of the predicted positivity/neutrality by the LinearSVC on the training tweets as well as the human-labeled tweets. This metric is particularly impactful in the context of the extension because of the use of the predicted probability of positivity/neutrality as the slider. The distribution of predictions could therefore be very influential on the content that is displayed. To construct the plots below 100k random training (in addition to the 100 human-labeled tweets) tweets were visualized using seaborn&rsquo;s kdeplot. In both sets of tweets, the LinearSVC&rsquo;s predictions follow a similar pattern: a large portion of probability density around the 50-60% mark, which likely indicates little notable sentiment due to a very neutral tweet or a case where the unigrams/bigrams in the tweet are not present in the tf-idf matrix. We elected to define 55% as the base, default case for the extension as a result of this. We also notice a significant spike, particularly when examining the negatively labeled training tweets, from 0-20% probability. From this, we decided to set the minimum value of the slider to 20% . Thus, even when the user is comfortable seeing most negativity, tweets that are below 20% positive probability are still filtered due to the very high probability that they are true negative tweets. We observe the same phenomenon with the human-labeled tweets, with a large amount of probability density around 50-60%. This is the case in true negative tweets as well, indicating that a large portion of false negatives is occurring at that probability prediction - as noted above, we think this is due to tweets tokens that fall outside of the vocabulary established by the training data.</span></p><p class="c2"><span class="c0"></span></p><h3 class="c26" id="h.9h8sau6fylt3"><span>Word/Topic Filtering</span></h3><p class="c7"><span>To handle the word filter aspect of the extension, we looked to apply Latent Dirichlet Allocation (LDA) to add words of similar meaning to the filter.</span></p><h4 class="c14" id="h.bz0t0zbleixo"><span class="c3">Gensim</span></h4><p class="c7"><span class="c0">Our initial thought was to use Gensim. We created a dictionary of the tokens and then a corpus of the tweets as a bag of words. From there we trained a LDA model. This took an extremely long amount of time to run, and once it was finished running (even at only 10 topics), the topics were full of jumbled words and we felt that it wouldn&rsquo;t be very accurate. The file size was also large and it did not seem as if this would be the route to take to get this into the extension.</span></p><h4 class="c14" id="h.fwwvcuer5wyr"><span class="c3">Thesaurus</span></h4><p class="c7"><span>Since Gensim wasn&rsquo;t going to work for our particular application, we decided to take a different approach using a thesaurus. We found a thesaurus in JSON format with hundreds of thousands of words. We took that thesaurus and lemmatized it so that the format of the words in the JSON file would match the same format as if a word from a tweet was passed by it. How it works is that when a user adds a filter word to the extension, the extension adds all of the synonyms of that word behind the scenes to the filter. Then, when a tweet is loaded, all of the words are checked for the filter word(s) and their synonyms. If there are any hits, the extension blocks the tweet.</span></p><p class="c2"><span class="c0"></span></p><h2 class="c13" id="h.dscmy5708fgr"><span class="c19">Ethics of Removing Posts</span></h2><p class="c7"><span class="c0">The concept of social media filter bubbles (11), in which a social media company feeding recommended content to a user or a user themselves filtering out content they don&rsquo;t want to see, was on our minds when developing this extension. Through filtering and curating content, we could end up painting an inaccurate picture of reality to our users; for example, one can imagine a situation where a news article about a catastrophic event and responses to it from other users could disappear from the feed of someone using our extension. In designing our extension, we have to balance this reality with the potential benefits of removing negative content, such as improved mental health for social media users. In the interest of pursuing these benefits while also realizing that there is potential value to users even in filtered content, the ideal design for our model would be one that is fully transparent, while leaving the ability to see filtered content fully up to the user.</span></p><p class="c2"><span class="c0"></span></p><p class="c7"><span class="c0">When testing our extension, we experimented with printing filtered tweets to the console so they could be examined upon filtering for a qualitative sense of the extent of filtering. We think this could be a potential solution to ethical issues with our extension, particularly provided that we warn users of the potential for sensitive or undesirable content in what we are filtering. Overall, we think in the case of negativity, the potential benefits outweigh the potential issues, especially if we are able to be completely transparent about what is being filtered. Additionally, since the model isn&rsquo;t perfect, there will be instances where it removes posts from the feed that aren&rsquo;t negative (and leave some that are). To alert users of this, we included a disclaimer in the readme that mentions this. We wanted to ensure that the users are in control of what gets filtered and to what extent with the slider and the filter words.</span></p><h2 class="c13" id="h.2l3qeenkholf"><span class="c19">Conclusion</span></h2><h3 class="c26" id="h.8trqlcttcw1v"><span class="c4">Where to go from here</span></h3><p class="c7"><span class="c0">There are numerous ways we can advance this project in the future. This project can be extended to other social media platforms, be more intuitive and learn from what the user wants hidden, as well as provide a way for the user to see what was hidden (if they wish). Also, there is always the opportunity for continuous improvement of the models. More robust topic modeling would be a starting point by trying to create an efficient model for topic filtering. This may be able to be accomplished by experimenting with different ways of chaining models together.</span></p><p class="c2"><span class="c0"></span></p><h3 class="c26" id="h.vj1skqpv1ql8"><span class="c4">Github Links</span></h3><p class="c7"><span>Github for Models: </span><span class="c5"><a class="c11" href="https://www.google.com/url?q=https://github.com/mphillipsjr96/SocialMedia_Content_Filter&amp;sa=D&amp;source=editors&amp;ust=1639968847022000&amp;usg=AOvVaw0IaG3gtXWwREjqg2PZsMj0">https://github.com/mphillipsjr96/SocialMedia_Content_Filter</a></span><span class="c0">&nbsp;</span></p><p class="c7"><span>Github for Extension: </span><span class="c5"><a class="c11" href="https://www.google.com/url?q=https://github.com/drkinder/content-filter-chrome-extension&amp;sa=D&amp;source=editors&amp;ust=1639968847022000&amp;usg=AOvVaw2LczcKBkxDDraxKeIJ2VX0">https://github.com/drkinder/content-filter-chrome-extension</a></span><span class="c0">&nbsp;</span></p><p class="c7"><span>Github for API: </span><span class="c5"><a class="c11" href="https://www.google.com/url?q=https://github.com/drkinder/content-filter-api&amp;sa=D&amp;source=editors&amp;ust=1639968847023000&amp;usg=AOvVaw1etUEYczXcZxBHi7qI6u0u">https://github.com/drkinder/content-filter-api</a></span></p><h2 class="c13" id="h.fs16ydmebo5n"><span class="c19">Contributions</span></h2><p class="c7"><span class="c0">Building and Deploying the API on Google Cloud - Dylan Kinder</span></p><p class="c7"><span class="c0">Building the Content Filter Chrome Extension - Dylan Kinder</span></p><p class="c7"><span class="c0">High Level System Flowchart - Dylan Kinder</span></p><p class="c7"><span class="c0">Developing Sentiment Models - Michael Phillips</span></p><p class="c7"><span class="c0">Developing Thesaurus Logic - Michael Phillips</span></p><p class="c7"><span class="c0">Developing GloVE/FastText Preprocessing/Models - Ryan Maloney</span></p><p class="c7"><span class="c0">Development of Human-Labeled Test Set, Analysis of Results with LinearSVC - Ryan Maloney</span></p><p class="c7"><span class="c0">Report Writing - Dylan Kinder, Michael Phillips, Ryan Maloney</span></p><h2 class="c13" id="h.d1zv3ur01c5v"><span class="c19">Resources</span></h2><p class="c7"><span>Google Cloud Build - </span><span class="c5"><a class="c11" href="https://www.google.com/url?q=https://cloud.google.com/build/docs/concepts&amp;sa=D&amp;source=editors&amp;ust=1639968847025000&amp;usg=AOvVaw1qH13JIYsCD84bWrDOlXHn">https://cloud.google.com/build/docs/concepts</a></span></p><p class="c7"><span>Google Cloud Run - </span><span class="c5"><a class="c11" href="https://www.google.com/url?q=https://cloud.google.com/run/docs/concepts&amp;sa=D&amp;source=editors&amp;ust=1639968847025000&amp;usg=AOvVaw3dKN3WVl1JkXgUBbzBP3OG">https://cloud.google.com/run/docs/concepts</a></span></p><p class="c7"><span>Chrome Extensions - </span><span class="c5"><a class="c11" href="https://www.google.com/url?q=https://developer.chrome.com/docs/extensions/&amp;sa=D&amp;source=editors&amp;ust=1639968847026000&amp;usg=AOvVaw1SGzvg6csv98faPz6k1Ask">https://developer.chrome.com/docs/extensions/</a></span></p><p class="c7"><span>FastAPI Python Library - </span><span class="c5"><a class="c11" href="https://www.google.com/url?q=https://fastapi.tiangolo.com/&amp;sa=D&amp;source=editors&amp;ust=1639968847027000&amp;usg=AOvVaw24iP30VuNveuDWSVyGM8Q5">https://fastapi.tiangolo.com/</a></span></p><p class="c7"><span>Langdetect Python Library - </span><span class="c5"><a class="c11" href="https://www.google.com/url?q=https://pypi.org/project/langdetect/&amp;sa=D&amp;source=editors&amp;ust=1639968847027000&amp;usg=AOvVaw1nE1i9wG-UEdeaSXCH9A1t">https://pypi.org/project/langdetect/</a></span></p><p class="c7"><span>Numpy Python Library - </span><span class="c5"><a class="c11" href="https://www.google.com/url?q=https://numpy.org/doc/&amp;sa=D&amp;source=editors&amp;ust=1639968847027000&amp;usg=AOvVaw2kqGU9dIRXFoVunjsyMuQv">https://numpy.org/doc/</a></span></p><p class="c7"><span>Open Office Thesaurus - </span><span class="c5"><a class="c11" href="https://www.google.com/url?q=https://www.openoffice.org/lingucomponent/thesaurus.html&amp;sa=D&amp;source=editors&amp;ust=1639968847028000&amp;usg=AOvVaw0kpwfShG7JPEZ22vMflYYf">https://www.openoffice.org/lingucomponent/thesaurus.html</a></span></p><p class="c7"><span>Pandas Python Library - </span><span class="c5"><a class="c11" href="https://www.google.com/url?q=https://pandas.pydata.org/docs/&amp;sa=D&amp;source=editors&amp;ust=1639968847028000&amp;usg=AOvVaw0hZRAlcyo8H2TiFLfi9XPA">https://pandas.pydata.org/docs/</a></span></p><p class="c7"><span>Gensim Python Library - </span><span class="c5"><a class="c11" href="https://www.google.com/url?q=https://radimrehurek.com/gensim/auto_examples/index.html&amp;sa=D&amp;source=editors&amp;ust=1639968847029000&amp;usg=AOvVaw078qCHrjFnQ5FZXt0hyl2-">https://radimrehurek.com/gensim/auto_examples/index.html</a></span></p><p class="c7"><span>Scikit-learn Python Library - </span><span class="c5"><a class="c11" href="https://www.google.com/url?q=https://scikit-learn.org/stable/&amp;sa=D&amp;source=editors&amp;ust=1639968847029000&amp;usg=AOvVaw2EYge2sg8SW8zIl_ayJtOP">https://scikit-learn.org/stable/</a></span></p><p class="c7"><span>Tweet Preprocessor Python Library - </span><span class="c5"><a class="c11" href="https://www.google.com/url?q=https://github.com/s/preprocessor&amp;sa=D&amp;source=editors&amp;ust=1639968847030000&amp;usg=AOvVaw3SOVWRVwf6pEmiEcaEAVYl">https://github.com/s/preprocessor</a></span></p><p class="c7"><span>VADER Sentiment Analysis - </span><span class="c5"><a class="c11" href="https://www.google.com/url?q=https://github.com/cjhutto/vaderSentiment&amp;sa=D&amp;source=editors&amp;ust=1639968847031000&amp;usg=AOvVaw3F3cBdAAlOqbePiQJDJOgl">https://github.com/cjhutto/vaderSentiment</a></span></p><p class="c7"><span>Seaborn Visualization - </span><span class="c5"><a class="c11" href="https://www.google.com/url?q=https://seaborn.pydata.org/&amp;sa=D&amp;source=editors&amp;ust=1639968847031000&amp;usg=AOvVaw0tZcgI2dVLpzln0KUFJLTF">https://seaborn.pydata.org/</a></span></p><p class="c7"><span>Altair Visualization - </span><span class="c5"><a class="c11" href="https://www.google.com/url?q=https://altair-viz.github.io/index.html&amp;sa=D&amp;source=editors&amp;ust=1639968847032000&amp;usg=AOvVaw1IkZyDYahoG02cXGTndoHo">https://altair-viz.github.io/index.html</a></span></p><p class="c7"><span>GloVE Word Embeddings Trained on 2B Tweets - </span><span class="c5"><a class="c11" href="https://www.google.com/url?q=https://nlp.stanford.edu/projects/glove/&amp;sa=D&amp;source=editors&amp;ust=1639968847032000&amp;usg=AOvVaw0haXmdLMNX03fKw6sB9RKl">https://nlp.stanford.edu/projects/glove/</a></span></p><p class="c7"><span>FastText English Language Model - </span><span class="c5"><a class="c11" href="https://www.google.com/url?q=https://fasttext.cc/docs/en/crawl-vectors.html&amp;sa=D&amp;source=editors&amp;ust=1639968847033000&amp;usg=AOvVaw1lPH5dsA0sWie7JxzjJsZU">https://fasttext.cc/docs/en/crawl-vectors.html</a></span></p><h2 class="c13" id="h.vmhdmni3l5bf"><span class="c19">Citations</span></h2><ol class="c43 lst-kix_1aefkzsvu2l5-0 start" start="1"><li class="c7 c17 li-bullet-0"><span class="c5"><a class="c11" href="https://www.google.com/url?q=https://journals.sagepub.com/doi/10.1177/1359104518775154&amp;sa=D&amp;source=editors&amp;ust=1639968847034000&amp;usg=AOvVaw3oSekzqRDvM7V3Nx7f4NkL">O&rsquo;Reilly, M., Dogra, N., Whiteman, N., Hughes, J., Eruyar, S., &amp; Reilly, P. (2018). Is social media bad for mental health and wellbeing? Exploring the perspectives of adolescents. Clinical Child Psychology and Psychiatry, 23(4), 601&ndash;613.</a></span></li><li class="c7 c17 li-bullet-0"><span class="c5"><a class="c11" href="https://www.google.com/url?q=https://www.forbes.com/sites/petersuciu/2019/11/15/does-negativity-drive-users-off-social-media/?sh%3D238533016dfb&amp;sa=D&amp;source=editors&amp;ust=1639968847034000&amp;usg=AOvVaw2zSDaZM-1DiOzROBZ6ixES">Suciu, P. (2019) Does Negativity Drive Users Off Social Media? </a></span><span class="c5 c21"><a class="c11" href="https://www.google.com/url?q=https://www.forbes.com/sites/petersuciu/2019/11/15/does-negativity-drive-users-off-social-media/?sh%3D238533016dfb&amp;sa=D&amp;source=editors&amp;ust=1639968847035000&amp;usg=AOvVaw0Db_1zcgSfjcDtpqmbguOG">Forbes Magazine</a></span><span class="c5"><a class="c11" href="https://www.google.com/url?q=https://www.forbes.com/sites/petersuciu/2019/11/15/does-negativity-drive-users-off-social-media/?sh%3D238533016dfb&amp;sa=D&amp;source=editors&amp;ust=1639968847035000&amp;usg=AOvVaw0Db_1zcgSfjcDtpqmbguOG">.</a></span></li><li class="c7 c17 li-bullet-0"><span class="c5 c38"><a class="c11" href="https://www.google.com/url?q=http://oro.open.ac.uk/40660/&amp;sa=D&amp;source=editors&amp;ust=1639968847036000&amp;usg=AOvVaw04kVVKJyEnhEh9CfjbImsM">Saif, Hassan; Fern&aacute;ndez, Miriam; He, Yulan and Alani, Harith (2013). Evaluation datasets for Twitter sentiment analysis: a survey and &#8203;&#8203;a new dataset, the STS-Gold. </a></span><span class="c5 c21 c38"><a class="c11" href="https://www.google.com/url?q=http://oro.open.ac.uk/40660/&amp;sa=D&amp;source=editors&amp;ust=1639968847036000&amp;usg=AOvVaw04kVVKJyEnhEh9CfjbImsM">1st Interantional Workshop on Emotion and Sentiment in Social and Expressive Media: Approaches and Perspectives from AI (ESSEM 2013)</a></span><span class="c5 c38"><a class="c11" href="https://www.google.com/url?q=http://oro.open.ac.uk/40660/&amp;sa=D&amp;source=editors&amp;ust=1639968847036000&amp;usg=AOvVaw04kVVKJyEnhEh9CfjbImsM">, 3 Dec 2013, Turin, Italy.</a></span></li><li class="c7 c17 li-bullet-0"><span class="c5"><a class="c11" href="https://www.google.com/url?q=http://help.sentiment140.com/home&amp;sa=D&amp;source=editors&amp;ust=1639968847037000&amp;usg=AOvVaw3uoxpOgJotxIgcIbv40edO">http://help.sentiment140.com/home</a></span></li><li class="c7 c17 li-bullet-0"><span class="c5"><a class="c11" href="https://www.google.com/url?q=https://cs.stanford.edu/people/alecmgo/papers/TwitterDistantSupervision09.pdf&amp;sa=D&amp;source=editors&amp;ust=1639968847037000&amp;usg=AOvVaw3Xo2n5TD2qx5D7xqZXWlO3">Go, A., Bhayani, R., Huang, L. (2009). Twitter sentiment classification using distant supervision.</a></span></li><li class="c7 c17 li-bullet-0"><span class="c5"><a class="c11" href="https://www.google.com/url?q=https://nlp.stanford.edu/pubs/glove.pdf&amp;sa=D&amp;source=editors&amp;ust=1639968847038000&amp;usg=AOvVaw2H6O3NYDLAz2VK0kRC_L6F">Pennington, J., Socher, R., Manning, C. (2014). GloVE: Global Vectors for Word Representation. </a></span><span class="c5 c21"><a class="c11" href="https://www.google.com/url?q=https://nlp.stanford.edu/pubs/glove.pdf&amp;sa=D&amp;source=editors&amp;ust=1639968847038000&amp;usg=AOvVaw2H6O3NYDLAz2VK0kRC_L6F">Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing.</a></span><span class="c5"><a class="c11" href="https://www.google.com/url?q=https://nlp.stanford.edu/pubs/glove.pdf&amp;sa=D&amp;source=editors&amp;ust=1639968847038000&amp;usg=AOvVaw2H6O3NYDLAz2VK0kRC_L6F">&nbsp;Oct 2014, Doha, Qatar.</a></span></li><li class="c7 c17 li-bullet-0"><span class="c5"><a class="c11" href="https://www.google.com/url?q=https://arxiv.org/abs/1607.01759&amp;sa=D&amp;source=editors&amp;ust=1639968847039000&amp;usg=AOvVaw1I5WQpG3Of2vikaFwiF6s4">Joulin, A., Grave, E., Bojanowski, P., Mikolov, T. (2020). Bag of Tricks for Efficient Text Classification. </a></span><span class="c5 c21"><a class="c11" href="https://www.google.com/url?q=https://arxiv.org/abs/1607.01759&amp;sa=D&amp;source=editors&amp;ust=1639968847039000&amp;usg=AOvVaw1I5WQpG3Of2vikaFwiF6s4">CoRR</a></span><span class="c5"><a class="c11" href="https://www.google.com/url?q=https://arxiv.org/abs/1607.01759&amp;sa=D&amp;source=editors&amp;ust=1639968847039000&amp;usg=AOvVaw1I5WQpG3Of2vikaFwiF6s4">.</a></span></li><li class="c7 c17 li-bullet-0"><span class="c5"><a class="c11" href="https://www.google.com/url?q=https://arxiv.org/abs/1607.01759&amp;sa=D&amp;source=editors&amp;ust=1639968847040000&amp;usg=AOvVaw28otzApCsWMzYsmX7mfsJZ">Bojanowski, P., Grave, E., Joulin, A., Mikolov, T. (2016). Enriching Word Vectors with Subword Information. </a></span><span class="c5 c21"><a class="c11" href="https://www.google.com/url?q=https://arxiv.org/abs/1607.01759&amp;sa=D&amp;source=editors&amp;ust=1639968847040000&amp;usg=AOvVaw28otzApCsWMzYsmX7mfsJZ">CoRR</a></span><span class="c5"><a class="c11" href="https://www.google.com/url?q=https://arxiv.org/abs/1607.01759&amp;sa=D&amp;source=editors&amp;ust=1639968847040000&amp;usg=AOvVaw28otzApCsWMzYsmX7mfsJZ">.</a></span></li><li class="c7 c17 li-bullet-0"><span class="c5"><a class="c11" href="https://www.google.com/url?q=https://doi.org/10.1145/2939672.2939785&amp;sa=D&amp;source=editors&amp;ust=1639968847041000&amp;usg=AOvVaw0liaUYs1slu53yy0f1W0PH">Chen, T., &amp; Guestrin, C. (2016). XGBoost: A Scalable Tree Boosting System. In Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (pp. 785&ndash;794). New York, NY, USA: ACM. https://doi.org/10.1145/2939672.2939785</a></span></li><li class="c7 c17 li-bullet-0"><span class="c5"><a class="c11" href="https://www.google.com/url?q=http://comp.social.gatech.edu/papers/icwsm14.vader.hutto.pdf&amp;sa=D&amp;source=editors&amp;ust=1639968847042000&amp;usg=AOvVaw2j2qRgWP5ovb3YqMlCLe9l">Hutto, C.J. Gilbert, E. (2015). VADER: A Parsimonious Rule-based Model for Sentiment Analysis of Social Media Text. </a></span><span class="c5 c21"><a class="c11" href="https://www.google.com/url?q=http://comp.social.gatech.edu/papers/icwsm14.vader.hutto.pdf&amp;sa=D&amp;source=editors&amp;ust=1639968847042000&amp;usg=AOvVaw2j2qRgWP5ovb3YqMlCLe9l">Proceedings of the 8th International Conference on Weblogs and Social Media, ICWSM 2014.</a></span></li><li class="c7 c17 li-bullet-0"><span class="c5"><a class="c11" href="https://www.google.com/url?q=https://www.nbcnews.com/better/lifestyle/problem-social-media-reinforcement-bubbles-what-you-can-do-about-ncna1063896&amp;sa=D&amp;source=editors&amp;ust=1639968847042000&amp;usg=AOvVaw3gQoXaUeNofyXr6Eog6WGO">Gould, W.R. (2019). Are you in a social media bubble? Here&rsquo;s how to tell. NBC News</a></span></li></ol>
    </div>
    </body>
</html>
